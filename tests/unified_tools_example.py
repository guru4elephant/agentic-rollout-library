#!/usr/bin/env python3
"""
ç»Ÿä¸€å·¥å…·æ¥å£ç¤ºä¾‹
å±•ç¤ºå¦‚ä½•é€šè¿‡execution_modeé…ç½®åœ¨æœ¬åœ°å’ŒK8Sç¯å¢ƒä¹‹é—´åˆ‡æ¢ï¼Œ
è€Œä¸éœ€è¦ä¿®æ”¹Agentä»£ç æˆ–å·¥å…·åç§°ã€‚
"""

import asyncio
import logging
import sys
import os

# Add the parent directory to the path so we can import workers module
sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))

from workers.core import create_tool, create_agent
from workers.agents.general_agent import dump_trajectory
from workers.utils import create_llm_client

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# APIé…ç½®
API_KEY = os.getenv("LLM_API_KEY", "your-api-key-here")
BASE_URL = os.getenv("LLM_BASE_URL", "your-base-url-here")
#MODEL_NAME = os.getenv("LLM_MODEL_NAME", "claude-3-sonnet")
MODEL_NAME = os.getenv("LLM_MODEL_NAME", "gpt-4")

# K8Sé…ç½®
K8S_POD_NAME = "swebench-xarray-pod"


def create_tools_with_mode(execution_mode: str = "local", pod_name: str = None):
    """
    åˆ›å»ºå·¥å…·é›†åˆï¼Œé€šè¿‡execution_modeå‚æ•°æ§åˆ¶æ‰§è¡Œç¯å¢ƒ
    
    Args:
        execution_mode: "local" æˆ– "k8s"
        pod_name: K8S podåç§°ï¼ˆå½“execution_mode="k8s"æ—¶éœ€è¦ï¼‰
    
    Returns:
        å·¥å…·å­—å…¸
    """
    print(f"ğŸ”§ åˆ›å»ºå·¥å…· (æ‰§è¡Œæ¨¡å¼: {execution_mode})")
    
    # åŸºç¡€å·¥å…·é…ç½®
    base_configs = {
        "timeout": 30,
        "execution_mode": execution_mode
    }
    
    # å¦‚æœæ˜¯K8Sæ¨¡å¼ï¼Œæ·»åŠ podé…ç½®
    if execution_mode == "k8s":
        if not pod_name:
            raise ValueError("K8Sæ¨¡å¼éœ€è¦æä¾›pod_name")
        base_configs.update({
            "pod_name": pod_name,
            "namespace": "default"
        })
        print(f"   K8Sç›®æ ‡Pod: {pod_name}")
    
    # åˆ›å»ºå·¥å…·ï¼ˆå·¥å…·åç§°ä¿æŒä¸å˜ï¼‰
    tools = {
        "bash_executor": create_tool("BashExecutor", base_configs.copy()),
        # "file_editor": create_tool("FileEditor", base_configs.copy()),  # æš‚æ—¶æ³¨é‡Šï¼Œç­‰å¾…é‡æ„å®Œæˆ
        # "search": create_tool("Search", base_configs.copy()),  # æš‚æ—¶æ³¨é‡Šï¼Œç­‰å¾…é‡æ„å®Œæˆ
        "finish": create_tool("Finish")
    }
    
    print(f"   åˆ›å»ºäº† {len(tools)} ä¸ªå·¥å…·: {list(tools.keys())}")
    return tools


async def run_local_task():
    """è¿è¡Œæœ¬åœ°ä»»åŠ¡ç¤ºä¾‹"""
    print("\n=== æœ¬åœ°æ‰§è¡Œæ¨¡å¼ç¤ºä¾‹ ===")
    
    # 1. åˆ›å»ºLLMå®¢æˆ·ç«¯
    llm_client = create_llm_client(API_KEY, BASE_URL, MODEL_NAME, debug=True)
    
    try:
        # 2. åˆ›å»ºæœ¬åœ°å·¥å…·
        tools = create_tools_with_mode(execution_mode="local")
        
        # 3. åˆ›å»ºGeneralAgent
        agent = create_agent("General", {
            "max_rounds": 20,
            "system_prompt": """ä½ æ˜¯ä¸€ä¸ªç³»ç»Ÿä¿¡æ¯æ”¶é›†ä¸“å®¶ã€‚è¯·è·å–æœ¬åœ°ç³»ç»Ÿçš„åŸºæœ¬ä¿¡æ¯ï¼š

ä½¿ç”¨ReActæ¡†æ¶ï¼š
1. Thought: åˆ†æéœ€è¦æ‰§è¡Œä»€ä¹ˆå‘½ä»¤
2. Action: ä½¿ç”¨bash_executorå·¥å…·æ‰§è¡Œå‘½ä»¤
3. é‡å¤ç›´åˆ°è·å–å®Œæ•´ä¿¡æ¯

è¯·è·å–ï¼š
1. å½“å‰ç›®å½•å†…å®¹ (ls -la)
2. ç³»ç»Ÿä¿¡æ¯ (uname -a)
3. å½“å‰ç”¨æˆ· (whoami)
4. Pythonç‰ˆæœ¬ (python3 --version)

æœ€åä½¿ç”¨finishå·¥å…·æä¾›æ€»ç»“æŠ¥å‘Šã€‚""",
            "termination_tool_names": ["finish"]
        })
        
        # 4. é…ç½®å·¥å…·å¹¶æ‰§è¡Œ
        agent.set_tools(tools)
        print(f"   GeneralAgentå·²é…ç½® {len(agent.tools)} ä¸ªå·¥å…·")
        
        trajectory = await agent.run_trajectory(
            prompt="è¯·è·å–æœ¬åœ°ç³»ç»Ÿçš„åŸºæœ¬ä¿¡æ¯å¹¶ç”ŸæˆæŠ¥å‘Šã€‚",
            llm_generate_func=llm_client.generate,
            request_id="local_system_info_001"
        )
        
        # 5. æ˜¾ç¤ºç»“æœ
        print(f"\nâœ… æœ¬åœ°ä»»åŠ¡å®Œæˆ!")
        print(f"   è½¨è¿¹çŠ¶æ€: {'å®Œæˆ' if trajectory.is_completed else 'æœªå®Œæˆ'}")
        print(f"   æ€»æ­¥æ•°: {len(trajectory.steps)}")
        
        # è·å–æœ€ç»ˆæŠ¥å‘Š
        final_answer = None
        for step in reversed(trajectory.steps):
            if step.tool_name == "finish" and step.tool_result:
                final_answer = step.tool_result.get("answer")
                break
        
        if final_answer:
            print(f"\n=== æœ¬åœ°ç³»ç»Ÿä¿¡æ¯æŠ¥å‘Š ===")
            print(final_answer)
        
        # 6. ä¿å­˜è½¨è¿¹æ–‡ä»¶
        import datetime
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        json_filename = f"tests/local_system_info_trajectory_{timestamp}.json"
        txt_filename = f"tests/local_system_info_trajectory_{timestamp}.txt"
        
        dump_trajectory(trajectory, json_filename, "json")
        dump_trajectory(trajectory, txt_filename, "txt")
        print(f"\nğŸ’¾ è½¨è¿¹å·²ä¿å­˜åˆ° {json_filename} å’Œ {txt_filename}")
        
        return trajectory
        
    finally:
        await llm_client.close()


async def run_k8s_task():
    """è¿è¡ŒK8Sä»»åŠ¡ç¤ºä¾‹"""
    print("\n=== K8Sæ‰§è¡Œæ¨¡å¼ç¤ºä¾‹ ===")
    
    # 1. åˆ›å»ºLLMå®¢æˆ·ç«¯
    llm_client = create_llm_client(API_KEY, BASE_URL, MODEL_NAME, debug=True)
    
    try:
        # 2. åˆ›å»ºK8Så·¥å…·
        tools = create_tools_with_mode(execution_mode="k8s", pod_name=K8S_POD_NAME)
        
        # 3. åˆ›å»ºGeneralAgentï¼ˆç›¸åŒçš„Agentä»£ç ï¼‰
        agent = create_agent("General", {
            "max_rounds": 5,
            "system_prompt": f"""ä½ æ˜¯ä¸€ä¸ªKubernetesç³»ç»Ÿç›‘æ§ä¸“å®¶ã€‚è¯·è·å–Pod {K8S_POD_NAME} çš„åŸºæœ¬ä¿¡æ¯ï¼š

ä½¿ç”¨ReActæ¡†æ¶ï¼š
1. Thought: åˆ†æéœ€è¦æ‰§è¡Œä»€ä¹ˆå‘½ä»¤
2. Action: ä½¿ç”¨bash_executorå·¥å…·åœ¨Podå†…æ‰§è¡Œå‘½ä»¤
3. é‡å¤ç›´åˆ°è·å–å®Œæ•´ä¿¡æ¯

è¯·è·å–ï¼š
1. Podå†…å½“å‰ç›®å½•å†…å®¹ (ls -la)
2. Podç³»ç»Ÿä¿¡æ¯ (uname -a)
3. Podå†…å½“å‰ç”¨æˆ· (whoami)
4. Podå†…Pythonç‰ˆæœ¬ (python3 --version)
5. Podå†…å­˜ä¿¡æ¯ (free -h)

æœ€åä½¿ç”¨finishå·¥å…·æä¾›PodçŠ¶æ€æ€»ç»“æŠ¥å‘Šã€‚""",
            "termination_tool_names": ["finish"]
        })
        
        # 4. é…ç½®å·¥å…·å¹¶æ‰§è¡Œï¼ˆç›¸åŒçš„æ¥å£ï¼‰
        agent.set_tools(tools)
        print(f"   GeneralAgentå·²é…ç½® {len(agent.tools)} ä¸ªå·¥å…·")
        
        trajectory = await agent.run_trajectory(
            prompt=f"è¯·è·å–æœ¬åœ°ç³»ç»Ÿçš„åŸºæœ¬ä¿¡æ¯å¹¶ç”ŸæˆæŠ¥å‘Šã€‚",
            llm_generate_func=llm_client.generate,
            request_id="k8s_system_info_001"
        )
        
        # 5. æ˜¾ç¤ºç»“æœ
        print(f"\nâœ… K8Sä»»åŠ¡å®Œæˆ!")
        print(f"   è½¨è¿¹çŠ¶æ€: {'å®Œæˆ' if trajectory.is_completed else 'æœªå®Œæˆ'}")
        print(f"   æ€»æ­¥æ•°: {len(trajectory.steps)}")
        
        # è·å–æœ€ç»ˆæŠ¥å‘Š
        final_answer = None
        for step in reversed(trajectory.steps):
            if step.tool_name == "finish" and step.tool_result:
                final_answer = step.tool_result.get("answer")
                break
        
        if final_answer:
            print(f"\n=== K8S Podä¿¡æ¯æŠ¥å‘Š ===")
            print(final_answer)
        
        # 6. ä¿å­˜è½¨è¿¹æ–‡ä»¶
        import datetime
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        json_filename = f"tests/k8s_system_info_trajectory_{timestamp}.json"
        txt_filename = f"tests/k8s_system_info_trajectory_{timestamp}.txt"
        
        dump_trajectory(trajectory, json_filename, "json")
        dump_trajectory(trajectory, txt_filename, "txt")
        print(f"\nğŸ’¾ è½¨è¿¹å·²ä¿å­˜åˆ° {json_filename} å’Œ {txt_filename}")
        
        return trajectory
        
    finally:
        await llm_client.close()


async def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºç»Ÿä¸€å·¥å…·æ¥å£çš„å¼ºå¤§ä¹‹å¤„"""
    print("ğŸš€ ç»Ÿä¸€å·¥å…·æ¥å£ç¤ºä¾‹")
    print("=" * 60)
    print("""
ğŸ“‹ æœ¬ç¤ºä¾‹å±•ç¤ºï¼š
1. ç›¸åŒçš„Agentä»£ç å¯ä»¥åœ¨æœ¬åœ°å’ŒK8Sç¯å¢ƒæ‰§è¡Œ
2. é€šè¿‡execution_modeé…ç½®åˆ‡æ¢æ‰§è¡Œç¯å¢ƒ
3. Agentæ— éœ€çŸ¥é“å·¥å…·çš„åº•å±‚å®ç°ç»†èŠ‚
4. å·¥å…·åç§°å’Œæ¥å£ä¿æŒä¸€è‡´

APIé…ç½®:
- Model: claude-sonnet-4-20250514
- Base URL: http://211.23.3.237:27544/

æ‰§è¡Œç¯å¢ƒ:
- æœ¬åœ°æ¨¡å¼: execution_mode="local"
- K8Sæ¨¡å¼: execution_mode="k8s", pod_name="swebench-xarray-pod"
    """)
    
    try:
        # è¿è¡Œæœ¬åœ°ä»»åŠ¡
        local_trajectory = await run_local_task()
        
        print("\n" + "=" * 60)
        
        # è¿è¡ŒK8Sä»»åŠ¡
        k8s_trajectory = await run_k8s_task()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ¼”ç¤ºå®Œæˆï¼")
        print(f"âœ… æœ¬åœ°ä»»åŠ¡: {len(local_trajectory.steps)} æ­¥")
        print(f"âœ… K8Sä»»åŠ¡: {len(k8s_trajectory.steps)} æ­¥")
        print(f"ğŸ’¾ è½¨è¿¹æ–‡ä»¶: æ¯ä¸ªä»»åŠ¡éƒ½ä¿å­˜äº†å®Œæ•´çš„JSONå’ŒTXTæ ¼å¼è½¨è¿¹æ–‡ä»¶")
        print("""
ğŸ’¡ å…³é”®ä¼˜åŠ¿ï¼š
- Agentä»£ç å®Œå…¨ç›¸åŒ
- å·¥å…·æ¥å£ç»Ÿä¸€
- é…ç½®é©±åŠ¨çš„æ‰§è¡Œç¯å¢ƒåˆ‡æ¢
- å¯¹Agenté€æ˜çš„åº•å±‚å®ç°
- è‡ªåŠ¨ä¿å­˜å®Œæ•´çš„æ‰§è¡Œè½¨è¿¹ï¼ˆä¸æˆªæ–­ï¼‰
        """)
        
    except Exception as e:
        logger.error(f"æ¼”ç¤ºæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    print("""
ğŸ”§ ç»Ÿä¸€å·¥å…·æ¥å£æ¶æ„è¯´æ˜:

ä¼ ç»Ÿæ–¹å¼:
- BashExecutorTool (æœ¬åœ°)
- K8sBashExecutorTool (K8S)
- Agentéœ€è¦çŸ¥é“ä½¿ç”¨å“ªä¸ªå·¥å…·

æ–°çš„ç»Ÿä¸€æ–¹å¼:
- BashExecutorTool (æ”¯æŒexecution_modeé…ç½®)
  - execution_mode="local" -> æœ¬åœ°æ‰§è¡Œ
  - execution_mode="k8s" -> K8Sæ‰§è¡Œ
- Agentä½¿ç”¨ç›¸åŒçš„å·¥å…·åç§°å’Œæ¥å£
- åº•å±‚å®ç°å¯¹Agenté€æ˜
    """)
    
    # æ£€æŸ¥ä¾èµ–
    try:
        import openai
    except ImportError:
        print("âŒ éœ€è¦å®‰è£…openaiåº“: pip install openai")
        sys.exit(1)
    
    asyncio.run(main())
