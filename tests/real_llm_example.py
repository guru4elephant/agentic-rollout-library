#!/usr/bin/env python3
"""
ä½¿ç”¨çœŸå®LLM APIçš„GeneralAgentç¤ºä¾‹
è·å–podç¯å¢ƒå†…çš„CPUåˆ©ç”¨ç‡å’Œå†…å­˜ä½¿ç”¨æƒ…å†µ

ç¤ºä¾‹å±•ç¤ºå¦‚ä½•ä½¿ç”¨LLMAPIClientä¸å„ç§LLMæä¾›å•†çš„APIè¿›è¡Œäº¤äº’
"""

import asyncio
import logging
import sys
import os

# Add the parent directory to the path so we can import workers module
sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))

from workers.core import create_tool, create_agent
from workers.agents.general_agent import dump_trajectory
from workers.utils import create_llm_client

# Check if kodo is available for K8S execution
try:
    from kodo import KubernetesManager
    K8S_AVAILABLE = True
except ImportError:
    K8S_AVAILABLE = False
    print("âŒ K8Så·¥å…·ä¸å¯ç”¨ï¼Œè¯·ç¡®ä¿å®‰è£…äº†kodoä¾èµ–")
    print("   pip install git+https://github.com/baidubce/kodo.git")
    exit(1)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# APIé…ç½®
API_KEY = os.getenv("LLM_API_KEY", "your-api-key-here")
BASE_URL = os.getenv("LLM_BASE_URL", "your-base-url-here")
MODEL_NAME = os.getenv("LLM_MODEL_NAME", "claude-3-sonnet")

# K8Sé…ç½®
K8S_POD_NAME = "swebench-xarray-pod"




async def run_k8s_pod_monitoring_task():
    """è¿è¡ŒK8S Podç›‘æ§ä»»åŠ¡"""
    print("=== K8S Podç›‘æ§ä»»åŠ¡ - ä½¿ç”¨çœŸå®LLM API ===")
    
    # 1. åˆ›å»ºLLMå®¢æˆ·ç«¯
    llm_client = create_llm_client(
        api_key=API_KEY,
        base_url=BASE_URL,
        model=MODEL_NAME,
        debug=True,
        max_retries=3
    )
    
    try:
        # 2. åˆ›å»ºK8Så·¥å…·ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„æ‰§è¡Œæ¨¡å¼é…ç½®ï¼‰
        print("\n1. åˆ›å»ºK8Så·¥å…·...")
        k8s_config = {
            "execution_mode": "k8s",
            "pod_name": K8S_POD_NAME,
            "namespace": "default",
            "timeout": 30
        }
        
        tools = {
            "bash_executor": create_tool("BashExecutor", k8s_config.copy()),
            "finish": create_tool("Finish")
        }
        print(f"   åˆ›å»ºäº† {len(tools)} ä¸ªK8Så·¥å…·: {list(tools.keys())}")
        print(f"   ç›®æ ‡Pod: {K8S_POD_NAME}")
        
        # 3. åˆ›å»ºGeneralAgent
        print("\n2. åˆ›å»ºGeneralAgent...")
        agent = create_agent("General", {
            "max_rounds": 8,
            "system_prompt": f"""ä½ æ˜¯ä¸€ä¸ªKubernetesç³»ç»Ÿç›‘æ§ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯è·å–æŒ‡å®šPod ({K8S_POD_NAME}) ç¯å¢ƒå†…çš„CPUåˆ©ç”¨ç‡å’Œå†…å­˜ä½¿ç”¨æƒ…å†µã€‚

ä½¿ç”¨ReActæ¡†æ¶ï¼š
1. Thought: åˆ†æéœ€è¦æ‰§è¡Œä»€ä¹ˆå‘½ä»¤æ¥è·å–ç³»ç»Ÿä¿¡æ¯
2. Action: ä½¿ç”¨K8Så·¥å…·åœ¨Podå†…æ‰§è¡Œç›¸å…³å‘½ä»¤
3. é‡å¤ç›´åˆ°è·å–åˆ°å®Œæ•´çš„ç³»ç»Ÿä¿¡æ¯

ä½ å¯ä»¥ä½¿ç”¨çš„å·¥å…·ï¼š
- bash_executor: åœ¨Podå†…æ‰§è¡Œbashå‘½ä»¤è·å–ç³»ç»Ÿä¿¡æ¯ï¼ˆé€šè¿‡K8S execution_modeï¼‰
- finish: å®Œæˆä»»åŠ¡å¹¶æä¾›æœ€ç»ˆæŠ¥å‘Š

è¯·è·å–ä»¥ä¸‹ä¿¡æ¯ï¼š
1. CPUä½¿ç”¨ç‡ (å¯ä»¥ä½¿ç”¨top, ps, /proc/statç­‰)
2. å†…å­˜ä½¿ç”¨æƒ…å†µ (å¯ä»¥ä½¿ç”¨free, /proc/meminfoç­‰)  
3. ç³»ç»Ÿè´Ÿè½½ (å¯ä»¥ä½¿ç”¨uptime, /proc/loadavgç­‰)
4. ç£ç›˜ä½¿ç”¨æƒ…å†µ (å¯ä»¥ä½¿ç”¨dfå‘½ä»¤)
5. Podçš„åŸºæœ¬ä¿¡æ¯å’Œè¿è¡ŒçŠ¶æ€

æœ€åæä¾›ä¸€ä¸ªå®Œæ•´çš„Podç³»ç»ŸçŠ¶æ€æŠ¥å‘Šã€‚""",
            "termination_tool_names": ["finish"]
        })
        
        # 4. é…ç½®å·¥å…·
        agent.set_tools(tools)
        print(f"   GeneralAgentå·²é…ç½® {len(agent.tools)} ä¸ªå·¥å…·")
        
        # 5. æ‰§è¡ŒK8S Podç›‘æ§ä»»åŠ¡
        print(f"\n3. å¼€å§‹æ‰§è¡ŒK8S Podç›‘æ§ä»»åŠ¡...")
        print(f"   ç›®æ ‡Pod: {K8S_POD_NAME}")
        print("   (è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´ï¼ŒLLMæ­£åœ¨åˆ†æå’Œæ‰§è¡ŒK8Så‘½ä»¤)")
        
        trajectory = await agent.run_trajectory(
            prompt=f"è¯·è·å–Kubernetes Pod '{K8S_POD_NAME}' ç¯å¢ƒå†…çš„CPUåˆ©ç”¨ç‡ã€å†…å­˜ä½¿ç”¨æƒ…å†µã€ç³»ç»Ÿè´Ÿè½½ã€ç£ç›˜ä½¿ç”¨æƒ…å†µå’ŒPodåŸºæœ¬ä¿¡æ¯ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„Podç³»ç»ŸçŠ¶æ€æŠ¥å‘Šã€‚",
            llm_generate_func=llm_client.generate,
            request_id="k8s_pod_monitoring_001"
        )
        
        # 6. æ˜¾ç¤ºç»“æœ
        print(f"\n4. ä»»åŠ¡å®Œæˆ!")
        print(f"   è½¨è¿¹çŠ¶æ€: {'å®Œæˆ' if trajectory.is_completed else 'æœªå®Œæˆ'}")
        print(f"   æ€»æ­¥æ•°: {len(trajectory.steps)}")
        print(f"   æ€»tokens: {trajectory.total_tokens}")
        
        # 7. æ˜¾ç¤ºæ‰§è¡Œè¿‡ç¨‹å’Œç»“æœ
        print("\n=== æ‰§è¡Œè¿‡ç¨‹ ===")
        for i, step in enumerate(trajectory.steps, 1):
            print(f"\nStep {i}: {step.step_type.value.upper()}")
            if len(step.content) > 200:
                print(f"Content: {step.content[:200]}...")
            else:
                print(f"Content: {step.content}")
            
            if step.tool_name:
                print(f"Tool: {step.tool_name}")
                if step.tool_result and isinstance(step.tool_result, dict):
                    if "result" in step.tool_result:
                        result = step.tool_result["result"]
                        if isinstance(result, str) and len(result) > 300:
                            print(f"Result: {result[:300]}...")
                        else:
                            print(f"Result: {result}")
        
        # 8. è·å–æœ€ç»ˆæŠ¥å‘Š
        final_answer = None
        final_reasoning = None
        
        for step in reversed(trajectory.steps):
            if step.tool_name == "finish" and step.tool_result:
                final_answer = step.tool_result.get("answer")
                final_reasoning = step.tool_result.get("reasoning")
                break
        
        if final_answer:
            print(f"\n=== æœ€ç»ˆç³»ç»ŸçŠ¶æ€æŠ¥å‘Š ===")
            print(final_answer)
            if final_reasoning:
                print(f"\n=== åˆ†æè¿‡ç¨‹ ===")
                print(final_reasoning)
        
        # 9. ä¿å­˜è½¨è¿¹
        import datetime
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        json_filename = f"tests/k8s_pod_monitoring_trajectory_{timestamp}.json"
        txt_filename = f"tests/k8s_pod_monitoring_trajectory_{timestamp}.txt"
        
        dump_trajectory(trajectory, json_filename, "json")
        dump_trajectory(trajectory, txt_filename, "txt")
        print(f"\nè½¨è¿¹å·²ä¿å­˜åˆ° {json_filename} å’Œ {txt_filename}")
        
        return trajectory
        
    except Exception as e:
        logger.error(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise
    
    finally:
        # æ¸…ç†èµ„æº
        await llm_client.close()


async def test_api_connection():
    """æµ‹è¯•APIè¿æ¥"""
    print("=== æµ‹è¯•APIè¿æ¥ ===")
    
    client = create_llm_client(
        api_key=API_KEY,
        base_url=BASE_URL,
        model=MODEL_NAME,
        debug=False,
        max_retries=1
    )
    
    try:
        # ç®€å•çš„æµ‹è¯•æ¶ˆæ¯
        test_messages = [
            {"role": "user", "content": "Hello, can you respond with 'API connection successful'?"}
        ]
        
        response = await client.generate(test_messages, max_tokens=50)
        print(f"APIæµ‹è¯•å“åº”: {response}")
        
        if "successful" in response.lower() or "connection" in response.lower():
            print("âœ… APIè¿æ¥æµ‹è¯•æˆåŠŸ!")
            return True
        else:
            print("âš ï¸ APIè¿æ¥å¯èƒ½æœ‰é—®é¢˜ï¼Œä½†æ”¶åˆ°äº†å“åº”")
            return True
            
    except Exception as e:
        print(f"âŒ APIè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    finally:
        await client.close()


async def main():
    """ä¸»å‡½æ•°"""
    print("K8S Podç›‘æ§ä»»åŠ¡ - ä½¿ç”¨çœŸå®LLM API")
    print("=" * 50)
    
    try:
        # é¦–å…ˆæµ‹è¯•APIè¿æ¥
        if not await test_api_connection():
            print("APIè¿æ¥æµ‹è¯•å¤±è´¥ï¼Œæ— æ³•ç»§ç»­æ‰§è¡Œä»»åŠ¡")
            return
        
        print("\n" + "=" * 50)
        
        # æ‰§è¡ŒK8S Podç›‘æ§ä»»åŠ¡
        await run_k8s_pod_monitoring_task()
        
        print("\nâœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆ!")
        
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    print("""
    ğŸ³ K8S Podç›‘æ§ä»»åŠ¡è¯´æ˜:
    
    æœ¬ç¤ºä¾‹å°†ä½¿ç”¨GeneralAgentå’ŒçœŸå®çš„LLM APIæ¥ï¼š
    1. è¿æ¥åˆ°æ‚¨æä¾›çš„LLM APIç«¯ç‚¹
    2. åˆ›å»ºé…ç½®äº†K8Så·¥å…·çš„GeneralAgent
    3. è®©Agentè‡ªåŠ¨è·å–æŒ‡å®šPodç¯å¢ƒçš„ç³»ç»Ÿä¿¡æ¯ï¼š
       - CPUåˆ©ç”¨ç‡
       - å†…å­˜ä½¿ç”¨æƒ…å†µ  
       - ç³»ç»Ÿè´Ÿè½½
       - ç£ç›˜ä½¿ç”¨æƒ…å†µ
       - PodåŸºæœ¬ä¿¡æ¯å’Œè¿è¡ŒçŠ¶æ€
    4. ç”Ÿæˆå®Œæ•´çš„Podç³»ç»ŸçŠ¶æ€æŠ¥å‘Š
    
    Agentå°†ä½¿ç”¨ReActæ¡†æ¶ï¼Œé€šè¿‡K8Så·¥å…·åœ¨Podå†…æ‰§è¡Œå‘½ä»¤è·å–ä¿¡æ¯ã€‚
    
    APIé…ç½®:
    - Model: claude-sonnet-4-20250514
    - Base URL: http://211.23.3.237:27544/
    - è¶…æ—¶: 60ç§’
    
    K8Sé…ç½®:
    - Pod Name: swebench-xarray-pod
    """)
    
    # æ£€æŸ¥requiredçš„openaiåº“
    try:
        import openai
    except ImportError:
        print("âŒ éœ€è¦å®‰è£…openaiåº“: pip install openai")
        sys.exit(1)
    
    asyncio.run(main())