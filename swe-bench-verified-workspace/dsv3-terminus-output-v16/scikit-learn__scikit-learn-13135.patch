diff --git a/debug_kmeans.py b/debug_kmeans.py
new file mode 100644
index 000000000..40e0c3042
--- /dev/null
+++ b/debug_kmeans.py
@@ -0,0 +1,21 @@
+import numpy as np
+from sklearn.cluster import KMeans
+
+# Test the kmeans clustering with the problematic data
+X = np.array([0, 0.5, 2, 3, 9, 10]).reshape(-1, 1)
+
+# KMeans with 5 clusters
+km = KMeans(n_clusters=5, n_init=1)
+km.fit(X)
+
+centers = km.cluster_centers_[:, 0]
+print("Cluster centers:", centers)
+print("Sorted centers:", np.sort(centers))
+
+# Calculate bin edges (midpoints between centers)
+bin_edges = (centers[1:] + centers[:-1]) * 0.5
+print("Bin edges (unsorted):", bin_edges)
+print("Sorted bin edges:", np.sort(bin_edges))
+
+# Check if bin edges are monotonic
+print("Are bin edges monotonic increasing?", np.all(np.diff(bin_edges) > 0))
\ No newline at end of file
diff --git a/reproduce_issue.py b/reproduce_issue.py
new file mode 100644
index 000000000..8c100578c
--- /dev/null
+++ b/reproduce_issue.py
@@ -0,0 +1,27 @@
+import numpy as np
+from sklearn.preprocessing import KBinsDiscretizer
+
+# Reproduce the issue described in the GitHub issue
+X = np.array([0, 0.5, 2, 3, 9, 10]).reshape(-1, 1)
+
+# with 5 bins
+print("Testing with 5 bins...")
+est = KBinsDiscretizer(n_bins=5, strategy='kmeans', encode='ordinal')
+try:
+    Xt = est.fit_transform(X)
+    print("Success! No error occurred.")
+    print("Transformed data:", Xt.ravel())
+except Exception as e:
+    print(f"Error occurred: {e}")
+    print(f"Error type: {type(e).__name__}")
+
+# Also test with 3 bins to see if it works normally
+print("\nTesting with 3 bins...")
+est3 = KBinsDiscretizer(n_bins=3, strategy='kmeans', encode='ordinal')
+try:
+    Xt3 = est3.fit_transform(X)
+    print("Success! No error occurred.")
+    print("Transformed data:", Xt3.ravel())
+except Exception as e:
+    print(f"Error occurred: {e}")
+    print(f"Error type: {type(e).__name__}")
\ No newline at end of file
diff --git a/sklearn/preprocessing/_discretization.py b/sklearn/preprocessing/_discretization.py
index dd969c12b..a6b884a7e 100644
--- a/sklearn/preprocessing/_discretization.py
+++ b/sklearn/preprocessing/_discretization.py
@@ -172,6 +172,8 @@ class KBinsDiscretizer(BaseEstimator, TransformerMixin):
                 # 1D k-means procedure
                 km = KMeans(n_clusters=n_bins[jj], init=init, n_init=1)
                 centers = km.fit(column[:, None]).cluster_centers_[:, 0]
+                # Sort the centers to ensure bin edges are monotonically increasing
+                centers.sort()
                 bin_edges[jj] = (centers[1:] + centers[:-1]) * 0.5
                 bin_edges[jj] = np.r_[col_min, bin_edges[jj], col_max]
 
diff --git a/test_edge_cases.py b/test_edge_cases.py
new file mode 100644
index 000000000..6e5e1e95f
--- /dev/null
+++ b/test_edge_cases.py
@@ -0,0 +1,38 @@
+import numpy as np
+from sklearn.preprocessing import KBinsDiscretizer
+
+def test_case(name, X, n_bins):
+    print(f"\nTesting {name}:")
+    print(f"Data: {X.ravel()}")
+    print(f"n_bins: {n_bins}")
+    
+    est = KBinsDiscretizer(n_bins=n_bins, strategy='kmeans', encode='ordinal')
+    try:
+        Xt = est.fit_transform(X)
+        print("Success! No error occurred.")
+        print("Transformed data:", Xt.ravel())
+        print("Bin edges:", est.bin_edges_[0])
+        # Check if bin edges are monotonic
+        bin_edges = est.bin_edges_[0]
+        is_monotonic = np.all(np.diff(bin_edges) > 0)
+        print("Bin edges are monotonic:", is_monotonic)
+        return True
+    except Exception as e:
+        print(f"Error occurred: {e}")
+        return False
+
+# Test various edge cases
+test_cases = [
+    ("Original issue case", np.array([0, 0.5, 2, 3, 9, 10]).reshape(-1, 1), 5),
+    ("More bins than data points", np.array([1, 2, 3]).reshape(-1, 1), 4),
+    ("Almost identical values", np.array([1.0, 1.0001, 1.0002]).reshape(-1, 1), 3),
+    ("Large range", np.array([0, 1000, 2000, 3000]).reshape(-1, 1), 4),
+    ("Negative values", np.array([-10, -5, 0, 5, 10]).reshape(-1, 1), 3),
+]
+
+all_passed = True
+for name, X, n_bins in test_cases:
+    passed = test_case(name, X, n_bins)
+    all_passed = all_passed and passed
+
+print(f"\nAll tests passed: {all_passed}")
\ No newline at end of file
diff --git a/test_original_issue.py b/test_original_issue.py
new file mode 100644
index 000000000..16a5cdf23
--- /dev/null
+++ b/test_original_issue.py
@@ -0,0 +1,44 @@
+import numpy as np
+from sklearn.preprocessing import KBinsDiscretizer
+
+# Test the exact case from the GitHub issue
+X = np.array([0, 0.5, 2, 3, 9, 10]).reshape(-1, 1)
+
+print("Testing the exact case from GitHub issue:")
+print("Data:", X.ravel())
+print("n_bins: 5")
+print("strategy: kmeans")
+
+est = KBinsDiscretizer(n_bins=5, strategy='kmeans', encode='ordinal')
+try:
+    Xt = est.fit_transform(X)
+    print("✓ Success! No error occurred.")
+    print("Transformed data:", Xt.ravel())
+    print("Bin edges:", est.bin_edges_[0])
+    
+    # Verify bin edges are monotonic
+    bin_edges = est.bin_edges_[0]
+    is_monotonic = np.all(np.diff(bin_edges) > 0)
+    print("Bin edges are monotonic:", is_monotonic)
+    
+    # Verify that np.digitize works with these bin edges
+    test_values = np.array([0, 0.5, 2, 3, 9, 10])
+    eps = 1e-8 + 1e-5 * np.abs(test_values)
+    digitized = np.digitize(test_values + eps, bin_edges[1:])
+    print("np.digitize test passed:", np.array_equal(digitized, Xt.ravel()))
+    
+except Exception as e:
+    print("✗ Error occurred:", e)
+    print("Error type:", type(e).__name__)
+
+# Test with various bin counts to ensure robustness
+print("\nTesting with various bin counts:")
+for n_bins in range(2, 7):
+    try:
+        est = KBinsDiscretizer(n_bins=n_bins, strategy='kmeans', encode='ordinal')
+        Xt = est.fit_transform(X)
+        bin_edges = est.bin_edges_[0]
+        is_monotonic = np.all(np.diff(bin_edges) > 0)
+        print(f"n_bins={n_bins}: ✓ Success, monotonic={is_monotonic}")
+    except Exception as e:
+        print(f"n_bins={n_bins}: ✗ Error - {e}")
\ No newline at end of file
diff --git a/test_other_strategies.py b/test_other_strategies.py
new file mode 100644
index 000000000..4637efcfe
--- /dev/null
+++ b/test_other_strategies.py
@@ -0,0 +1,24 @@
+import numpy as np
+from sklearn.preprocessing import KBinsDiscretizer
+
+X = np.array([0, 0.5, 2, 3, 9, 10]).reshape(-1, 1)
+
+print("Testing all strategies with the problematic data:")
+strategies = ['uniform', 'quantile', 'kmeans']
+
+for strategy in strategies:
+    print(f"\nTesting strategy: {strategy}")
+    try:
+        est = KBinsDiscretizer(n_bins=5, strategy=strategy, encode='ordinal')
+        Xt = est.fit_transform(X)
+        print("✓ Success! No error occurred.")
+        print(f"Transformed data: {Xt.ravel()}")
+        print(f"Bin edges: {est.bin_edges_[0]}")
+        
+        # Check if bin edges are monotonic
+        bin_edges = est.bin_edges_[0]
+        is_monotonic = np.all(np.diff(bin_edges) > 0)
+        print(f"Bin edges are monotonic: {is_monotonic}")
+        
+    except Exception as e:
+        print(f"✗ Error occurred: {e}")
\ No newline at end of file