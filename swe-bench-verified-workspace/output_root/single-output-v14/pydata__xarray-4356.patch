diff --git a/debug_in_depth.py b/debug_in_depth.py
new file mode 100644
index 00000000..bfc88a05
--- /dev/null
+++ b/debug_in_depth.py
@@ -0,0 +1,34 @@
+import numpy as np
+from xarray.core import dtypes
+
+print("Debugging 'in' operator in depth...")
+print(f"NAT_TYPES: {dtypes.NAT_TYPES}")
+
+float64_dtype = np.dtype('float64')
+print(f"float64_dtype: {float64_dtype}")
+
+# Let's see what happens with the hash function
+print(f"hash(float64_dtype): {hash(float64_dtype)}")
+for nat_type in dtypes.NAT_TYPES:
+    print(f"hash({nat_type}): {hash(nat_type)}")
+
+# Let's check if there's some implicit conversion happening
+print(f"float64_dtype == dtypes.NAT_TYPES[0]: {float64_dtype == dtypes.NAT_TYPES[0]}")
+print(f"float64_dtype is dtypes.NAT_TYPES[0]: {float64_dtype is dtypes.NAT_TYPES[0]}")
+
+# Let's try to understand what the 'in' operator is actually doing
+# by implementing our own version
+def custom_in(obj, container):
+    for item in container:
+        if obj == item:
+            print(f"Found match: {obj} == {item}")
+            return True
+        else:
+            print(f"No match: {obj} != {item}")
+    return False
+
+print("Custom 'in' implementation:")
+result = custom_in(float64_dtype, dtypes.NAT_TYPES)
+print(f"Custom result: {result}")
+
+print("Built-in 'in' result:", float64_dtype in dtypes.NAT_TYPES)
\ No newline at end of file
diff --git a/debug_in_operator.py b/debug_in_operator.py
new file mode 100644
index 00000000..b6d0ad17
--- /dev/null
+++ b/debug_in_operator.py
@@ -0,0 +1,25 @@
+import numpy as np
+from xarray.core import dtypes
+
+print("Debugging 'in' operator behavior...")
+print(f"NAT_TYPES: {dtypes.NAT_TYPES}")
+
+# Test different ways to check membership
+float64_dtype = np.dtype('float64')
+
+# Method 1: Direct 'in' operator
+print(f"float64 in NAT_TYPES: {float64_dtype in dtypes.NAT_TYPES}")
+
+# Method 2: Check with any()
+print(f"any(float64 == nat_type): {any(float64_dtype == nat_type for nat_type in dtypes.NAT_TYPES)}")
+
+# Method 3: Manual iteration
+for i, nat_type in enumerate(dtypes.NAT_TYPES):
+    print(f"nat_type[{i}]: {nat_type}, equal: {float64_dtype == nat_type}")
+
+# Let's also check what happens with the actual result object
+import xarray as xr
+da = xr.DataArray([[1., np.nan, np.nan], [4, 5, 6]])
+result = da.sum(["dim_0", "dim_1"], min_count=5)
+print(f"result.dtype: {result.dtype}")
+print(f"result.dtype in NAT_TYPES: {result.dtype in dtypes.NAT_TYPES}")
\ No newline at end of file
diff --git a/debug_min_count.py b/debug_min_count.py
new file mode 100644
index 00000000..fc99da7f
--- /dev/null
+++ b/debug_min_count.py
@@ -0,0 +1,29 @@
+import xarray as xr
+import numpy as np
+
+print("Debugging min_count behavior...")
+
+# Test case: With NaN values and below min_count
+print("Test case: With NaN values and below min_count")
+da_with_nan = xr.DataArray([[1., np.nan, np.nan], [4, 5, 6]])
+print("Original array:")
+print(da_with_nan.values)
+print(f"Number of non-NaN values: {np.sum(~np.isnan(da_with_nan.values))}")
+
+# Test with min_count=5 (should trigger nulling out since only 4 valid values)
+result = da_with_nan.sum(["dim_0", "dim_1"], min_count=5)
+print(f"Result with min_count=5: {result.values}")
+print(f"Result dtype: {result.dtype}")
+
+# Test with min_count=4 (exactly the number of valid values)
+result2 = da_with_nan.sum(["dim_0", "dim_1"], min_count=4)
+print(f"Result with min_count=4: {result2.values}")
+
+# Test with min_count=3 (below the number of valid values)
+result3 = da_with_nan.sum(["dim_0", "dim_1"], min_count=3)
+print(f"Result with min_count=3: {result3.values}")
+
+# Let's also test single dimension case
+print("\nSingle dimension test:")
+result_single = da_with_nan.sum("dim_0", min_count=3)  # Should work
+print(f"Single dim result with min_count=3: {result_single.values}")
\ No newline at end of file
diff --git a/debug_nat_types.py b/debug_nat_types.py
new file mode 100644
index 00000000..29ad544e
--- /dev/null
+++ b/debug_nat_types.py
@@ -0,0 +1,16 @@
+import numpy as np
+from xarray.core import dtypes
+
+print("Debugging NAT_TYPES comparison...")
+print(f"NAT_TYPES: {dtypes.NAT_TYPES}")
+print(f"Type of NAT_TYPES: {type(dtypes.NAT_TYPES)}")
+
+# Test if float64 is in NAT_TYPES
+float64_dtype = np.dtype('float64')
+print(f"float64 dtype: {float64_dtype}")
+print(f"float64 in NAT_TYPES: {float64_dtype in dtypes.NAT_TYPES}")
+
+# Test individual elements
+for nat_type in dtypes.NAT_TYPES:
+    print(f"nat_type: {nat_type}, type: {type(nat_type)}")
+    print(f"float64 == nat_type: {float64_dtype == nat_type}")
\ No newline at end of file
diff --git a/debug_scalar.py b/debug_scalar.py
new file mode 100644
index 00000000..55c3dd96
--- /dev/null
+++ b/debug_scalar.py
@@ -0,0 +1,32 @@
+import xarray as xr
+import numpy as np
+
+print("Debugging scalar case behavior...")
+
+# Test case: With NaN values and below min_count
+da_with_nan = xr.DataArray([[1., np.nan, np.nan], [4, 5, 6]])
+print("Original array:")
+print(da_with_nan.values)
+print(f"Number of non-NaN values: {np.sum(~np.isnan(da_with_nan.values))}")
+
+# Let's see what the result looks like without min_count first
+result_no_min = da_with_nan.sum(["dim_0", "dim_1"])
+print(f"Result without min_count: {result_no_min.values}")
+print(f"Result dtype: {result_no_min.dtype}")
+print(f"Result ndim: {result_no_min.ndim}")
+print(f"Result shape: {result_no_min.shape}")
+
+# Now with min_count
+result_with_min = da_with_nan.sum(["dim_0", "dim_1"], min_count=5)
+print(f"Result with min_count=5: {result_with_min.values}")
+print(f"Result dtype: {result_with_min.dtype}")
+print(f"Result ndim: {result_with_min.ndim}")
+print(f"Result shape: {result_with_min.shape}")
+
+# Let's also check what mask.sum(axis) returns
+from xarray.core.nanops import _replace_nan
+a, mask = _replace_nan(da_with_nan.values, 0)
+print(f"Mask values: {mask}")
+print(f"Mask sum over all axes: {mask.sum()}")
+print(f"Total elements: {mask.size}")
+print(f"Valid elements: {mask.size - mask.sum()}")
\ No newline at end of file
diff --git a/final_test.py b/final_test.py
new file mode 100644
index 00000000..83099e6c
--- /dev/null
+++ b/final_test.py
@@ -0,0 +1,40 @@
+import xarray as xr
+import numpy as np
+
+print("Final comprehensive test...")
+
+# Test the original issue from GitHub
+print("\n1. Original GitHub issue:")
+da = xr.DataArray([[1., 2, 3], [4, 5, 6]])
+result = da.sum(["dim_0", "dim_1"], min_count=1)
+print(f"Result: {result.values}")
+assert result.values == 21.0
+
+# Test with NaN values
+print("\n2. With NaN values:")
+da_with_nan = xr.DataArray([[1., np.nan, 3], [4, 5, 6]])
+result = da_with_nan.sum(["dim_0", "dim_1"], min_count=5)  # 5 valid values
+print(f"Result: {result.values}")
+assert result.values == 19.0
+
+# Test with insufficient valid values
+print("\n3. Insufficient valid values:")
+da_with_nan = xr.DataArray([[1., np.nan, np.nan], [4, 5, 6]])
+result = da_with_nan.sum(["dim_0", "dim_1"], min_count=5)  # 4 valid values
+print(f"Result: {result.values}")
+assert np.isnan(result.values)
+
+# Test single dimension (should still work)
+print("\n4. Single dimension:")
+result = da.sum("dim_0", min_count=1)
+print(f"Result: {result.values}")
+assert result.values.tolist() == [5.0, 7.0, 9.0]
+
+# Test all NaN
+print("\n5. All NaN:")
+da_all_nan = xr.DataArray([[np.nan, np.nan, np.nan], [np.nan, np.nan, np.nan]])
+result = da_all_nan.sum(["dim_0", "dim_1"], min_count=1)  # 0 valid values
+print(f"Result: {result.values}")
+assert np.isnan(result.values)
+
+print("\nAll tests passed! ✅")
\ No newline at end of file
diff --git a/reproduce_issue.py b/reproduce_issue.py
new file mode 100644
index 00000000..ae9913f6
--- /dev/null
+++ b/reproduce_issue.py
@@ -0,0 +1,17 @@
+import xarray as xr
+
+# Create a simple DataArray
+da = xr.DataArray([[1., 2, 3], [4, 5, 6]])
+
+print("DataArray:")
+print(da)
+print()
+
+# Try to reproduce the issue - sum with min_count and multiple dimensions
+try:
+    result = da.sum(["dim_0", "dim_1"], min_count=1)
+    print("Success! Result:")
+    print(result)
+except Exception as e:
+    print(f"Error: {e}")
+    print(f"Error type: {type(e).__name__}")
\ No newline at end of file
diff --git a/test_additional_cases.py b/test_additional_cases.py
new file mode 100644
index 00000000..baf183da
--- /dev/null
+++ b/test_additional_cases.py
@@ -0,0 +1,31 @@
+import xarray as xr
+import numpy as np
+
+print("Testing additional edge cases...")
+
+# Test case 1: Empty list of dimensions (should work like no axis specified)
+print("\n1. Empty list of dimensions:")
+da = xr.DataArray([[1., 2, 3], [4, 5, 6]])
+try:
+    result = da.sum([], min_count=1)
+    print(f"Result: {result.values}")
+except Exception as e:
+    print(f"Error: {e}")
+
+# Test case 2: Single element in list (should work like single axis)
+print("\n2. Single element in list:")
+result = da.sum(["dim_0"], min_count=1)
+print(f"Result: {result.values}")
+
+# Test case 3: Different order of dimensions
+print("\n3. Different order of dimensions:")
+result = da.sum(["dim_1", "dim_0"], min_count=1)
+print(f"Result: {result.values}")
+
+# Test case 4: Edge case with exactly min_count
+print("\n4. Exactly min_count:")
+da_with_nan = xr.DataArray([[1., np.nan, np.nan], [4, 5, 6]])
+result = da_with_nan.sum(["dim_0", "dim_1"], min_count=4)  # Exactly 4 valid values
+print(f"Result: {result.values}")
+
+print("\nAll additional tests completed!")
\ No newline at end of file
diff --git a/test_edge_cases.py b/test_edge_cases.py
new file mode 100644
index 00000000..5ea2c719
--- /dev/null
+++ b/test_edge_cases.py
@@ -0,0 +1,42 @@
+import xarray as xr
+import numpy as np
+
+print("Testing edge cases for min_count with multiple dimensions...")
+
+# Test case 1: Basic case with all valid values
+print("\n1. Basic case with all valid values:")
+da = xr.DataArray([[1., 2, 3], [4, 5, 6]])
+result = da.sum(["dim_0", "dim_1"], min_count=1)
+print(f"Result: {result.values}")
+
+# Test case 2: With NaN values but still above min_count
+print("\n2. With NaN values but still above min_count:")
+da_with_nan = xr.DataArray([[1., np.nan, 3], [4, 5, 6]])
+result = da_with_nan.sum(["dim_0", "dim_1"], min_count=3)  # 5 valid values, min_count=3
+print(f"Result: {result.values}")
+
+# Test case 3: With NaN values and below min_count
+print("\n3. With NaN values and below min_count:")
+da_with_nan = xr.DataArray([[1., np.nan, np.nan], [4, 5, 6]])
+result = da_with_nan.sum(["dim_0", "dim_1"], min_count=5)  # 4 valid values, min_count=5
+print(f"Result: {result.values}")
+
+# Test case 4: Single dimension (should still work)
+print("\n4. Single dimension (should still work):")
+result = da.sum("dim_0", min_count=1)
+print(f"Result: {result.values}")
+
+# Test case 5: All NaN values
+print("\n5. All NaN values:")
+da_all_nan = xr.DataArray([[np.nan, np.nan, np.nan], [np.nan, np.nan, np.nan]])
+result = da_all_nan.sum(["dim_0", "dim_1"], min_count=1)  # 0 valid values, min_count=1
+print(f"Result: {result.values}")
+
+# Test case 6: 3D array
+print("\n6. 3D array:")
+da_3d = xr.DataArray(np.random.rand(2, 3, 4))
+result = da_3d.sum(["dim_0", "dim_1"], min_count=1)
+print(f"Result shape: {result.shape}")
+print(f"Result: {result.values}")
+
+print("\nAll tests completed!")
\ No newline at end of file
diff --git a/test_nanprod.py b/test_nanprod.py
new file mode 100644
index 00000000..960f301b
--- /dev/null
+++ b/test_nanprod.py
@@ -0,0 +1,24 @@
+import xarray as xr
+import numpy as np
+
+print("Testing nanprod with min_count and multiple dimensions...")
+
+# Test nanprod with multiple dimensions
+da = xr.DataArray([[1., 2, 3], [4, 5, 6]])
+result = da.prod(["dim_0", "dim_1"], min_count=1)
+print(f"Product result: {result.values}")
+assert result.values == 720.0  # 1*2*3*4*5*6 = 720
+
+# Test nanprod with NaN values and min_count
+da_with_nan = xr.DataArray([[1., np.nan, 3], [4, 5, 6]])
+result = da_with_nan.prod(["dim_0", "dim_1"], min_count=5)  # 5 valid values
+print(f"Product with NaN result: {result.values}")
+assert result.values == 360.0  # 1*3*4*5*6 = 360
+
+# Test nanprod with insufficient valid values
+da_with_nan = xr.DataArray([[1., np.nan, np.nan], [4, 5, 6]])
+result = da_with_nan.prod(["dim_0", "dim_1"], min_count=5)  # 4 valid values
+print(f"Product with insufficient valid values: {result.values}")
+assert np.isnan(result.values)
+
+print("All nanprod tests passed! ✅")
\ No newline at end of file
diff --git a/xarray/core/nanops.py b/xarray/core/nanops.py
index 41c8d258..65fa8528 100644
--- a/xarray/core/nanops.py
+++ b/xarray/core/nanops.py
@@ -26,19 +26,23 @@ def _maybe_null_out(result, axis, mask, min_count=1):
     """
     xarray version of pandas.core.nanops._maybe_null_out
     """
-    if hasattr(axis, "__len__"):  # if tuple or list
-        raise ValueError(
-            "min_count is not available for reduction with more than one dimensions."
-        )
-
     if axis is not None and getattr(result, "ndim", False):
-        null_mask = (mask.shape[axis] - mask.sum(axis) - min_count) < 0
+        if hasattr(axis, "__len__"):  # if tuple or list
+            # Calculate total number of elements along reduction axes
+            total_elements = np.prod([mask.shape[ax] for ax in axis])
+        else:
+            total_elements = mask.shape[axis]
+        
+        null_mask = (total_elements - mask.sum(axis) - min_count) < 0
         if null_mask.any():
             dtype, fill_value = dtypes.maybe_promote(result.dtype)
             result = result.astype(dtype)
             result[null_mask] = fill_value
 
-    elif getattr(result, "dtype", None) not in dtypes.NAT_TYPES:
+    # Use explicit check instead of 'in' operator due to strange behavior with numpy dtypes
+    result_dtype = getattr(result, "dtype", None)
+    is_nat_type = any(result_dtype == nat_type for nat_type in dtypes.NAT_TYPES)
+    if result_dtype is not None and not is_nat_type:
         null_mask = mask.size - mask.sum()
         if null_mask < min_count:
             result = np.nan