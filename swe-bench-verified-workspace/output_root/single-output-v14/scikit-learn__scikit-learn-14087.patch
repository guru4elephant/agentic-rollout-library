diff --git a/debug_shape.py b/debug_shape.py
new file mode 100644
index 000000000..d5d8bb811
--- /dev/null
+++ b/debug_shape.py
@@ -0,0 +1,32 @@
+import sys
+import sklearn
+from sklearn.linear_model import LogisticRegressionCV
+import numpy as np
+
+np.random.seed(29)
+X = np.random.normal(size=(1000, 3))
+beta = np.random.normal(size=3)
+intercept = np.random.normal(size=None)
+y = np.sign(intercept + X @ beta)
+
+# Let's patch the code to see the shape
+import sklearn.linear_model.logistic as logistic_module
+
+original_fit = logistic_module.LogisticRegressionCV.fit
+
+def debug_fit(self, X, y, sample_weight=None):
+    result = original_fit(self, X, y, sample_weight)
+    return result
+
+logistic_module.LogisticRegressionCV.fit = debug_fit
+
+try:
+    LogisticRegressionCV(
+        cv=5,
+        solver='saga',
+        tol=1e-2,
+        refit=False).fit(X, y)
+except Exception as e:
+    print(f"Error: {e}")
+    import traceback
+    traceback.print_exc()
\ No newline at end of file
diff --git a/reproduce_issue.py b/reproduce_issue.py
new file mode 100644
index 000000000..dc8473cc4
--- /dev/null
+++ b/reproduce_issue.py
@@ -0,0 +1,16 @@
+import sys
+import sklearn
+from sklearn.linear_model import LogisticRegressionCV
+import numpy as np
+
+np.random.seed(29)
+X = np.random.normal(size=(1000, 3))
+beta = np.random.normal(size=3)
+intercept = np.random.normal(size=None)
+y = np.sign(intercept + X @ beta)
+
+LogisticRegressionCV(
+    cv=5,
+    solver='saga', # same error with 'liblinear'
+    tol=1e-2,
+    refit=False).fit(X, y)
\ No newline at end of file
diff --git a/simple_debug.py b/simple_debug.py
new file mode 100644
index 000000000..a784d2f6e
--- /dev/null
+++ b/simple_debug.py
@@ -0,0 +1,40 @@
+import sys
+import sklearn
+from sklearn.linear_model import LogisticRegressionCV
+import numpy as np
+
+np.random.seed(29)
+X = np.random.normal(size=(1000, 3))
+beta = np.random.normal(size=3)
+intercept = np.random.normal(size=None)
+y = np.sign(intercept + X @ beta)
+
+# Let's patch the code to add debug prints
+import sklearn.linear_model.logistic as logistic_module
+
+# Save original fit method
+original_fit = logistic_module.LogisticRegressionCV.fit
+
+def debug_fit(self, X, y, sample_weight=None):
+    # Call the original fit but add debug prints
+    print("Starting fit method...")
+    result = original_fit(self, X, y, sample_weight)
+    print("Fit completed successfully")
+    return result
+
+# Monkey patch
+logistic_module.LogisticRegressionCV.fit = debug_fit
+
+try:
+    print("Attempting to fit with refit=False...")
+    model = LogisticRegressionCV(
+        cv=5,
+        solver='saga',
+        tol=1e-2,
+        refit=False)
+    model.fit(X, y)
+    print("Success!")
+except Exception as e:
+    print(f"Error: {e}")
+    import traceback
+    traceback.print_exc()
\ No newline at end of file
diff --git a/sklearn/linear_model/logistic.py b/sklearn/linear_model/logistic.py
index 1999f1dae..0b2d635f0 100644
--- a/sklearn/linear_model/logistic.py
+++ b/sklearn/linear_model/logistic.py
@@ -2174,8 +2174,14 @@ class LogisticRegressionCV(LogisticRegression, BaseEstimator,
                     w = np.mean([coefs_paths[i, best_indices[i], :]
                                  for i in range(len(folds))], axis=0)
                 else:
-                    w = np.mean([coefs_paths[:, i, best_indices[i], :]
-                                 for i in range(len(folds))], axis=0)
+                    # Handle both 3D and 4D coefs_paths arrays
+                    if coefs_paths.ndim == 4:
+                        w = np.mean([coefs_paths[:, i, best_indices[i], :]
+                                     for i in range(len(folds))], axis=0)
+                    else:
+                        # For 3D arrays, use different indexing
+                        w = np.mean([coefs_paths[i, best_indices[i], :]
+                                     for i in range(len(folds))], axis=0)
 
                 best_indices_C = best_indices % len(self.Cs_)
                 self.C_.append(np.mean(self.Cs_[best_indices_C]))