diff --git a/debug_example_dotdot.py b/debug_example_dotdot.py
new file mode 100644
index 00000000..ff725ed2
--- /dev/null
+++ b/debug_example_dotdot.py
@@ -0,0 +1,17 @@
+from urllib3.util import parse_url
+
+# Test what parse_url returns for the problematic URL
+try:
+    result = parse_url("http://example..com")
+    print(f"parse_url result: {result}")
+    print(f"host: {result.host}")
+except Exception as e:
+    print(f"parse_url failed: {type(e).__name__}: {e}")
+
+# Test what happens when we try to extract the hostname
+try:
+    scheme, auth, host, port, path, query, fragment = parse_url("http://example..com")
+    print(f"Extracted host: {host}")
+    print(f"Host starts with dot: {host.startswith('.')}")
+except Exception as e:
+    print(f"Host extraction failed: {type(e).__name__}: {e}")
\ No newline at end of file
diff --git a/requests/adapters.py b/requests/adapters.py
index fe22ff45..dca09cba 100644
--- a/requests/adapters.py
+++ b/requests/adapters.py
@@ -28,6 +28,7 @@ from urllib3.exceptions import ReadTimeoutError
 from urllib3.exceptions import SSLError as _SSLError
 from urllib3.exceptions import ResponseError
 from urllib3.exceptions import LocationValueError
+from urllib3.exceptions import LocationParseError
 
 from .models import Response
 from .compat import urlparse, basestring
@@ -411,7 +412,7 @@ class HTTPAdapter(BaseAdapter):
 
         try:
             conn = self.get_connection(request.url, proxies)
-        except LocationValueError as e:
+        except (LocationValueError, LocationParseError) as e:
             raise InvalidURL(e, request=request)
 
         self.cert_verify(conn, request.url, verify, cert)
@@ -535,4 +536,7 @@ class HTTPAdapter(BaseAdapter):
             else:
                 raise
 
+        except LocationParseError as e:
+            raise InvalidURL(e, request=request)
+
         return self.build_response(request, resp)
diff --git a/requests/models.py b/requests/models.py
index e7d292d5..9fd33f12 100644
--- a/requests/models.py
+++ b/requests/models.py
@@ -403,7 +403,7 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):
                 host = self._get_idna_encoded_host(host)
             except UnicodeError:
                 raise InvalidURL('URL has an invalid label.')
-        elif host.startswith(u'*'):
+        elif host.startswith(u'*') or host.startswith(u'.') or '..' in host or host.endswith(u'.'):
             raise InvalidURL('URL has an invalid label.')
 
         # Carefully reconstruct the network location
diff --git a/test_edge_cases.py b/test_edge_cases.py
new file mode 100644
index 00000000..3e38e700
--- /dev/null
+++ b/test_edge_cases.py
@@ -0,0 +1,38 @@
+import requests
+
+# Test cases for invalid hostnames
+test_cases = [
+    "http://.example.com",  # Original issue
+    "http://*.example.com",  # Wildcard
+    "http://..example.com",  # Double dot
+    "http://example..com",  # Double dot in middle
+    "http://example.com.",  # Trailing dot
+]
+
+for url in test_cases:
+    try:
+        response = requests.get(url)
+        print(f"✓ {url} - Request succeeded (unexpected)")
+    except requests.exceptions.InvalidURL as e:
+        print(f"✓ {url} - Correctly raised InvalidURL: {e}")
+    except Exception as e:
+        print(f"✗ {url} - Unexpected exception: {type(e).__name__}: {e}")
+
+# Test cases for valid hostnames
+valid_cases = [
+    "http://example.com",
+    "http://sub.example.com",
+    "http://valid-host.com",
+]
+
+print("\nTesting valid URLs:")
+for url in valid_cases:
+    try:
+        response = requests.get(url, timeout=1)  # Short timeout to avoid hanging
+        print(f"✓ {url} - Request succeeded (expected)")
+    except requests.exceptions.Timeout:
+        print(f"✓ {url} - Request timed out (expected for invalid domain)")
+    except requests.exceptions.ConnectionError:
+        print(f"✓ {url} - Connection failed (expected for invalid domain)")
+    except Exception as e:
+        print(f"✗ {url} - Unexpected exception: {type(e).__name__}: {e}")
\ No newline at end of file