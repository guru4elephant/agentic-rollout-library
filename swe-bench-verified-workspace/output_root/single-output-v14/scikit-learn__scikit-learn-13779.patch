diff --git a/final_comprehensive_test.py b/final_comprehensive_test.py
new file mode 100644
index 000000000..0873e58f5
--- /dev/null
+++ b/final_comprehensive_test.py
@@ -0,0 +1,83 @@
+import numpy as np
+from sklearn.datasets import load_iris
+from sklearn.linear_model import LogisticRegression
+from sklearn.ensemble import RandomForestClassifier, VotingClassifier
+from sklearn.neighbors import KNeighborsClassifier
+
+# Comprehensive test to ensure the fix works correctly
+X, y = load_iris(return_X_y=True)
+
+print("Running comprehensive test for VotingClassifier with None estimators and sample weights...")
+
+# Test 1: Original issue reproduction
+print("\n1. Original issue scenario:")
+try:
+    voter = VotingClassifier(
+        estimators=[('lr', LogisticRegression()),
+                    ('rf', RandomForestClassifier())]
+    )
+    voter.fit(X, y, sample_weight=np.ones(y.shape))
+    voter.set_params(lr=None)
+    voter.fit(X, y, sample_weight=np.ones(y.shape))
+    print("   ✓ Success")
+except Exception as e:
+    print(f"   ✗ Failed: {e}")
+
+# Test 2: Multiple None estimators with sample weights
+print("\n2. Multiple None estimators with sample weights:")
+try:
+    voter = VotingClassifier(
+        estimators=[('lr', None), ('rf', RandomForestClassifier()), ('nb', None)]
+    )
+    voter.fit(X, y, sample_weight=np.ones(y.shape))
+    print("   ✓ Success")
+except Exception as e:
+    print(f"   ✗ Failed: {e}")
+
+# Test 3: Estimator that doesn't support sample weights (should still fail)
+print("\n3. Estimator that doesn't support sample weights:")
+try:
+    voter = VotingClassifier(
+        estimators=[('lr', LogisticRegression()), ('knn', KNeighborsClassifier())]
+    )
+    voter.fit(X, y, sample_weight=np.ones(y.shape))
+    print("   ✗ Should have failed but didn't")
+except ValueError as e:
+    if "does not support sample weights" in str(e):
+        print("   ✓ Correctly failed with expected error")
+    else:
+        print(f"   ✗ Failed with unexpected error: {e}")
+except Exception as e:
+    print(f"   ✗ Failed with unexpected error: {e}")
+
+# Test 4: Mixed scenario - None estimator + estimator that doesn't support sample weights
+print("\n4. None estimator + estimator that doesn't support sample weights:")
+try:
+    voter = VotingClassifier(
+        estimators=[('lr', None), ('knn', KNeighborsClassifier())]
+    )
+    voter.fit(X, y, sample_weight=np.ones(y.shape))
+    print("   ✗ Should have failed but didn't")
+except ValueError as e:
+    if "does not support sample weights" in str(e):
+        print("   ✓ Correctly failed with expected error")
+    else:
+        print(f"   ✗ Failed with unexpected error: {e}")
+except Exception as e:
+    print(f"   ✗ Failed with unexpected error: {e}")
+
+# Test 5: All None estimators (should fail)
+print("\n5. All None estimators:")
+try:
+    voter = VotingClassifier(estimators=[('lr', None), ('rf', None)])
+    voter.fit(X, y, sample_weight=np.ones(y.shape))
+    print("   ✗ Should have failed but didn't")
+except ValueError as e:
+    if "All estimators are None" in str(e):
+        print("   ✓ Correctly failed with expected error")
+    else:
+        print(f"   ✗ Failed with unexpected error: {e}")
+except Exception as e:
+    print(f"   ✗ Failed with unexpected error: {e}")
+
+print("\nComprehensive test completed!")
\ No newline at end of file
diff --git a/reproduce_issue.py b/reproduce_issue.py
new file mode 100644
index 000000000..3293c1aa0
--- /dev/null
+++ b/reproduce_issue.py
@@ -0,0 +1,22 @@
+import numpy as np
+from sklearn.datasets import load_iris
+from sklearn.linear_model import LogisticRegression
+from sklearn.ensemble import RandomForestClassifier, VotingClassifier
+
+# Reproduce the issue described in the GitHub issue
+X, y = load_iris(return_X_y=True)
+voter = VotingClassifier(
+    estimators=[('lr', LogisticRegression()),
+                ('rf', RandomForestClassifier())]
+)
+voter.fit(X, y, sample_weight=np.ones(y.shape))
+print("First fit successful")
+
+# Set one estimator to None and try to fit again with sample_weight
+voter.set_params(lr=None)
+try:
+    voter.fit(X, y, sample_weight=np.ones(y.shape))
+    print("Second fit with None estimator successful")
+except Exception as e:
+    print(f"Error occurred: {e}")
+    print(f"Error type: {type(e)}")
\ No newline at end of file
diff --git a/sklearn/ensemble/voting.py b/sklearn/ensemble/voting.py
index 7afa7180c..13accdcec 100644
--- a/sklearn/ensemble/voting.py
+++ b/sklearn/ensemble/voting.py
@@ -78,7 +78,7 @@ class _BaseVoting(_BaseComposition, TransformerMixin):
 
         if sample_weight is not None:
             for name, step in self.estimators:
-                if not has_fit_parameter(step, 'sample_weight'):
+                if step is not None and not has_fit_parameter(step, 'sample_weight'):
                     raise ValueError('Underlying estimator \'%s\' does not'
                                      ' support sample weights.' % name)
 
diff --git a/test_edge_cases.py b/test_edge_cases.py
new file mode 100644
index 000000000..bbf7d8a2f
--- /dev/null
+++ b/test_edge_cases.py
@@ -0,0 +1,61 @@
+import numpy as np
+from sklearn.datasets import load_iris
+from sklearn.linear_model import LogisticRegression
+from sklearn.ensemble import RandomForestClassifier, VotingClassifier
+
+# Test various edge cases
+X, y = load_iris(return_X_y=True)
+
+print("Testing edge cases for VotingClassifier with None estimators and sample weights...")
+
+# Test case 1: All estimators are None (should fail)
+print("\n1. Testing with all None estimators:")
+try:
+    voter = VotingClassifier(estimators=[('lr', None), ('rf', None)])
+    voter.fit(X, y, sample_weight=np.ones(y.shape))
+    print("   Unexpected success - should have failed!")
+except ValueError as e:
+    print(f"   Expected error: {e}")
+
+# Test case 2: One None estimator, no sample weights (should work)
+print("\n2. Testing with one None estimator, no sample weights:")
+try:
+    voter = VotingClassifier(estimators=[('lr', LogisticRegression()), ('rf', None)])
+    voter.fit(X, y)  # No sample weights
+    print("   Success with one None estimator, no sample weights")
+except Exception as e:
+    print(f"   Unexpected error: {e}")
+
+# Test case 3: One None estimator, with sample weights (should work after fix)
+print("\n3. Testing with one None estimator, with sample weights:")
+try:
+    voter = VotingClassifier(estimators=[('lr', LogisticRegression()), ('rf', None)])
+    voter.fit(X, y, sample_weight=np.ones(y.shape))
+    print("   Success with one None estimator and sample weights")
+except Exception as e:
+    print(f"   Unexpected error: {e}")
+
+# Test case 4: Multiple None estimators, one valid (should work)
+print("\n4. Testing with multiple None estimators, one valid:")
+try:
+    voter = VotingClassifier(estimators=[('lr', None), ('rf', RandomForestClassifier()), ('nb', None)])
+    voter.fit(X, y, sample_weight=np.ones(y.shape))
+    print("   Success with multiple None estimators, one valid")
+except Exception as e:
+    print(f"   Unexpected error: {e}")
+
+# Test case 5: Original issue reproduction
+print("\n5. Testing original issue scenario:")
+try:
+    voter = VotingClassifier(
+        estimators=[('lr', LogisticRegression()),
+                    ('rf', RandomForestClassifier())]
+    )
+    voter.fit(X, y, sample_weight=np.ones(y.shape))
+    voter.set_params(lr=None)
+    voter.fit(X, y, sample_weight=np.ones(y.shape))
+    print("   Success with original issue scenario")
+except Exception as e:
+    print(f"   Unexpected error: {e}")
+
+print("\nAll edge case tests completed!")
\ No newline at end of file