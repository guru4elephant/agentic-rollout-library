diff --git a/reproduce_issue.py b/reproduce_issue.py
new file mode 100644
index 000000000..0d994399f
--- /dev/null
+++ b/reproduce_issue.py
@@ -0,0 +1,54 @@
+#!/usr/bin/env python3
+"""
+Script to reproduce the SparseCoder max_iter issue
+"""
+import warnings
+import numpy as np
+from sklearn.decomposition import SparseCoder
+
+# Generate some test data
+resolution = 1024
+y = np.linspace(0, resolution - 1, resolution)
+first_quarter = y < resolution / 4
+y[first_quarter] = 3.
+y[np.logical_not(first_quarter)] = -1.
+
+# Create a dictionary
+def ricker_matrix(width, resolution, n_components):
+    """Dictionary of Ricker (Mexican hat) wavelets"""
+    centers = np.linspace(0, resolution - 1, n_components)
+    D = np.empty((n_components, resolution))
+    for i, center in enumerate(centers):
+        D[i] = np.exp(-(np.arange(resolution) - center)**2 / (2 * width**2))
+    D /= np.sqrt(np.sum(D ** 2, axis=1))[:, np.newaxis]
+    return D
+
+D = ricker_matrix(width=100, resolution=resolution, n_components=resolution // 3)
+
+print("Testing SparseCoder with lasso_cd algorithm...")
+print("This should produce a warning about max_iter/convergence")
+
+# Capture warnings
+with warnings.catch_warnings(record=True) as w:
+    warnings.simplefilter("always")
+    
+    # Create SparseCoder with lasso_cd algorithm
+    coder = SparseCoder(
+        dictionary=D, 
+        transform_algorithm='lasso_cd',
+        transform_alpha=2
+    )
+    
+    # Transform the data
+    x = coder.transform(y.reshape(1, -1))
+    
+    # Check if we got any warnings
+    if w:
+        print(f"Warnings captured: {len(w)}")
+        for warning in w:
+            print(f"Warning: {warning.message}")
+            print(f"Category: {warning.category}")
+    else:
+        print("No warnings captured")
+
+print("Test completed")
\ No newline at end of file
diff --git a/sklearn/decomposition/dict_learning.py b/sklearn/decomposition/dict_learning.py
index a318c957f..8c8f434be 100644
--- a/sklearn/decomposition/dict_learning.py
+++ b/sklearn/decomposition/dict_learning.py
@@ -865,7 +865,8 @@ class SparseCodingMixin(TransformerMixin):
                                   transform_algorithm='omp',
                                   transform_n_nonzero_coefs=None,
                                   transform_alpha=None, split_sign=False,
-                                  n_jobs=None, positive_code=False):
+                                  n_jobs=None, positive_code=False,
+                                  max_iter=1000):
         self.n_components = n_components
         self.transform_algorithm = transform_algorithm
         self.transform_n_nonzero_coefs = transform_n_nonzero_coefs
@@ -873,6 +874,7 @@ class SparseCodingMixin(TransformerMixin):
         self.split_sign = split_sign
         self.n_jobs = n_jobs
         self.positive_code = positive_code
+        self.max_iter = max_iter
 
     def transform(self, X):
         """Encode the data as a sparse combination of the dictionary atoms.