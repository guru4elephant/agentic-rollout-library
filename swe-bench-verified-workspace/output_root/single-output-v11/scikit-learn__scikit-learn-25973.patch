diff --git a/debug_cv.py b/debug_cv.py
new file mode 100644
index 000000000..f7feeb9f0
--- /dev/null
+++ b/debug_cv.py
@@ -0,0 +1,21 @@
+from sklearn.datasets import make_classification
+from sklearn.model_selection import LeaveOneGroupOut
+import numpy as np
+
+X, y = make_classification()
+groups = np.zeros_like(y, dtype=int)
+groups[y.size//2:] = 1
+
+cv = LeaveOneGroupOut()
+splits = cv.split(X, y, groups=groups)
+
+# Check if splits is an iterator and what it contains
+print("Type of splits:", type(splits))
+splits_list = list(splits)
+print("Number of splits:", len(splits_list))
+print("First split:", splits_list[0] if splits_list else "Empty")
+
+# The issue: if we try to use splits again, it's empty
+print("Trying to use splits again (should be empty):")
+splits_again = list(cv.split(X, y, groups=groups))
+print("Number of splits on second call:", len(splits_again))
\ No newline at end of file
diff --git a/debug_cv2.py b/debug_cv2.py
new file mode 100644
index 000000000..3fce48584
--- /dev/null
+++ b/debug_cv2.py
@@ -0,0 +1,30 @@
+from sklearn.datasets import make_classification
+from sklearn.feature_selection import SequentialFeatureSelector
+from sklearn.neighbors import KNeighborsClassifier
+from sklearn.model_selection import LeaveOneGroupOut
+from sklearn.model_selection._split import _CVIterableWrapper
+import numpy as np
+
+X, y = make_classification()
+
+groups = np.zeros_like(y, dtype=int)
+groups[y.size//2:] = 1
+
+cv = LeaveOneGroupOut()
+splits = cv.split(X, y, groups=groups)
+
+# Check what happens when we wrap the splits in _CVIterableWrapper
+print("Original splits type:", type(splits))
+wrapper = _CVIterableWrapper(splits)
+print("Wrapper splits:", wrapper.cv)
+print("Number of splits in wrapper:", len(wrapper.cv))
+
+# Try to iterate through the wrapper
+print("Iterating through wrapper splits:")
+for i, (train, test) in enumerate(wrapper.split()):
+    print(f"Split {i}: train={len(train)}, test={len(test)}")
+
+# Now let's see what happens when we use the original splits again
+print("Original splits after wrapping (should be empty if consumed):")
+splits_after = list(cv.split(X, y, groups=groups))
+print("Number of splits on fresh call:", len(splits_after))
\ No newline at end of file
diff --git a/debug_cv3.py b/debug_cv3.py
new file mode 100644
index 000000000..77545a0d0
--- /dev/null
+++ b/debug_cv3.py
@@ -0,0 +1,63 @@
+from sklearn.datasets import make_classification
+from sklearn.feature_selection import SequentialFeatureSelector
+from sklearn.neighbors import KNeighborsClassifier
+from sklearn.model_selection import LeaveOneGroupOut
+from sklearn.model_selection._validation import cross_val_score
+from sklearn.model_selection._split import check_cv
+import numpy as np
+
+X, y = make_classification()
+
+groups = np.zeros_like(y, dtype=int)
+groups[y.size//2:] = 1
+
+cv = LeaveOneGroupOut()
+splits = cv.split(X, y, groups=groups)
+
+# Check what check_cv returns
+checked_cv = check_cv(splits, y, classifier=True)
+print("Type of checked_cv:", type(checked_cv))
+
+# Check what indices returns
+indices = checked_cv.split(X, y, groups=groups)
+print("Type of indices:", type(indices))
+
+# Try to iterate through indices
+print("Iterating through indices:")
+indices_list = list(indices)
+print("Number of indices:", len(indices_list))
+for i, (train, test) in enumerate(indices_list):
+    print(f"Index {i}: train={len(train)}, test={len(test)}")
+
+# Now try cross_val_score directly
+print("Trying cross_val_score with splits:")
+try:
+    scores = cross_val_score(
+        KNeighborsClassifier(n_neighbors=5),
+        X,
+        y,
+        cv=splits,
+        scoring='accuracy'
+    )
+    print("Cross val scores:", scores)
+except Exception as e:
+    print("Error in cross_val_score:", e)
+    import traceback
+    traceback.print_exc()
+
+# Try with fresh splits
+print("Trying cross_val_score with fresh splits:")
+fresh_splits = cv.split(X, y, groups=groups)
+try:
+    scores = cross_val_score(
+        KNeighborsClassifier(n_neighbors=5),
+        X,
+        y,
+        cv=fresh_splits,
+        scoring='accuracy'
+    )
+    print("Cross val scores with fresh splits:", scores)
+except Exception as e:
+    print("Error in cross_val_score with fresh splits:", e)
+    import traceback
+    traceback.print_exc()
\ No newline at end of file
diff --git a/debug_cv4.py b/debug_cv4.py
new file mode 100644
index 000000000..a67fa291c
--- /dev/null
+++ b/debug_cv4.py
@@ -0,0 +1,37 @@
+from sklearn.datasets import make_classification
+from sklearn.model_selection import LeaveOneGroupOut
+from sklearn.model_selection._split import _CVIterableWrapper, check_cv
+import numpy as np
+
+X, y = make_classification()
+
+groups = np.zeros_like(y, dtype=int)
+groups[y.size//2:] = 1
+
+cv = LeaveOneGroupOut()
+
+# Test 1: Pass cv.split() directly to check_cv
+print("=== Test 1: Pass cv.split() directly ===")
+splits1 = cv.split(X, y, groups=groups)
+print("splits1 type:", type(splits1))
+checked_cv1 = check_cv(splits1, y, classifier=True)
+print("checked_cv1 type:", type(checked_cv1))
+print("checked_cv1.cv:", checked_cv1.cv)
+print("len(checked_cv1.cv):", len(checked_cv1.cv))
+
+# Test 2: Pass the cv object itself
+print("\n=== Test 2: Pass cv object ===")
+checked_cv2 = check_cv(cv, y, classifier=True)
+print("checked_cv2 type:", type(checked_cv2))
+indices2 = checked_cv2.split(X, y, groups=groups)
+print("indices2 type:", type(indices2))
+indices_list2 = list(indices2)
+print("len(indices_list2):", len(indices_list2))
+
+# Test 3: Create fresh splits and pass to check_cv
+print("\n=== Test 3: Fresh splits ===")
+splits3 = cv.split(X, y, groups=groups)
+checked_cv3 = check_cv(splits3, y, classifier=True)
+print("checked_cv3 type:", type(checked_cv3))
+print("checked_cv3.cv:", checked_cv3.cv)
+print("len(checked_cv3.cv):", len(checked_cv3.cv))
\ No newline at end of file
diff --git a/debug_cv5.py b/debug_cv5.py
new file mode 100644
index 000000000..92fa25a96
--- /dev/null
+++ b/debug_cv5.py
@@ -0,0 +1,70 @@
+from sklearn.datasets import make_classification
+from sklearn.neighbors import KNeighborsClassifier
+from sklearn.model_selection import LeaveOneGroupOut
+from sklearn.model_selection._validation import cross_validate
+from sklearn.model_selection._split import check_cv
+from sklearn.metrics import get_scorer
+import numpy as np
+
+X, y = make_classification()
+
+groups = np.zeros_like(y, dtype=int)
+groups[y.size//2:] = 1
+
+cv = LeaveOneGroupOut()
+splits = cv.split(X, y, groups=groups)
+
+# Mimic the exact flow of cross_validate
+checked_cv = check_cv(splits, y, classifier=True)
+print("checked_cv type:", type(checked_cv))
+print("checked_cv.cv:", checked_cv.cv)
+
+scorer = get_scorer('accuracy')
+print("scorer type:", type(scorer))
+
+indices = checked_cv.split(X, y, groups=groups)
+print("indices type:", type(indices))
+
+# Try to iterate through indices
+print("Iterating through indices:")
+indices_list = list(indices)
+print("Number of indices:", len(indices_list))
+
+# Try cross_validate directly
+print("Trying cross_validate with splits:")
+try:
+    results = cross_validate(
+        KNeighborsClassifier(n_neighbors=5),
+        X,
+        y,
+        cv=splits,
+        scoring={'score': scorer},
+        return_train_score=False,
+        return_estimator=False,
+        return_times=True
+    )
+    print("Cross validate results:", results)
+except Exception as e:
+    print("Error in cross_validate:", e)
+    import traceback
+    traceback.print_exc()
+
+# Try with fresh splits
+print("Trying cross_validate with fresh splits:")
+fresh_splits = cv.split(X, y, groups=groups)
+try:
+    results = cross_validate(
+        KNeighborsClassifier(n_neighbors=5),
+        X,
+        y,
+        cv=fresh_splits,
+        scoring={'score': scorer},
+        return_train_score=False,
+        return_estimator=False,
+        return_times=True
+    )
+    print("Cross validate results with fresh splits:", results)
+except Exception as e:
+    print("Error in cross_validate with fresh splits:", e)
+    import traceback
+    traceback.print_exc()
\ No newline at end of file
diff --git a/debug_cv6.py b/debug_cv6.py
new file mode 100644
index 000000000..dc7f3c39d
--- /dev/null
+++ b/debug_cv6.py
@@ -0,0 +1,36 @@
+from sklearn.datasets import make_classification
+from sklearn.model_selection import LeaveOneGroupOut
+import numpy as np
+
+X, y = make_classification()
+
+groups = np.zeros_like(y, dtype=int)
+groups[y.size//2:] = 1
+
+cv = LeaveOneGroupOut()
+splits = cv.split(X, y, groups=groups)
+
+# Show that the splits generator gets consumed
+print("First iteration through splits:")
+count1 = 0
+for train, test in splits:
+    count1 += 1
+    print(f"Split {count1}: train={len(train)}, test={len(test)}")
+
+print("Second iteration through splits (should be empty):")
+count2 = 0
+for train, test in splits:
+    count2 += 1
+    print(f"Split {count2}: train={len(train)}, test={len(test)}")
+
+print(f"First iteration count: {count1}")
+print(f"Second iteration count: {count2}")
+
+# Now test with fresh splits each time
+print("\nTesting with fresh splits each time:")
+for i in range(3):
+    fresh_splits = cv.split(X, y, groups=groups)
+    count = 0
+    for train, test in fresh_splits:
+        count += 1
+    print(f"Fresh splits iteration {i+1}: {count} splits")
\ No newline at end of file
diff --git a/reproduce_issue.py b/reproduce_issue.py
new file mode 100644
index 000000000..1c1d77750
--- /dev/null
+++ b/reproduce_issue.py
@@ -0,0 +1,19 @@
+from sklearn.datasets import make_classification
+from sklearn.feature_selection import SequentialFeatureSelector
+from sklearn.neighbors import KNeighborsClassifier
+from sklearn.model_selection import LeaveOneGroupOut
+
+import numpy as np
+
+X, y = make_classification()
+
+groups = np.zeros_like(y, dtype=int)
+groups[y.size//2:] = 1
+
+cv = LeaveOneGroupOut()
+splits = cv.split(X, y, groups=groups)
+
+clf = KNeighborsClassifier(n_neighbors=5)
+
+seq = SequentialFeatureSelector(clf, n_features_to_select=5, scoring='accuracy', cv=splits)
+seq.fit(X, y)
\ No newline at end of file
diff --git a/sklearn/feature_selection/_sequential.py b/sklearn/feature_selection/_sequential.py
index e983c55de..0adf3cd4e 100644
--- a/sklearn/feature_selection/_sequential.py
+++ b/sklearn/feature_selection/_sequential.py
@@ -8,12 +8,12 @@ import numpy as np
 import warnings
 
 from ._base import SelectorMixin
-from ..base import BaseEstimator, MetaEstimatorMixin, clone
+from ..base import BaseEstimator, MetaEstimatorMixin, clone, is_classifier
 from ..utils._param_validation import HasMethods, Hidden, Interval, StrOptions
 from ..utils._param_validation import RealNotInt
 from ..utils._tags import _safe_tags
 from ..utils.validation import check_is_fitted
-from ..model_selection import cross_val_score
+from ..model_selection import cross_val_score, check_cv
 from ..metrics import get_scorer_names
 
 
@@ -229,6 +229,9 @@ class SequentialFeatureSelector(SelectorMixin, MetaEstimatorMixin, BaseEstimator
         )
         n_features = X.shape[1]
 
+        # Preprocess cv parameter to handle iterables properly
+        self._cv = check_cv(self.cv, y, classifier=is_classifier(self.estimator))
+
         # FIXME: to be fixed in 1.3
         error_msg = (
             "n_features_to_select must be either 'auto', 'warn', "
@@ -309,7 +312,7 @@ class SequentialFeatureSelector(SelectorMixin, MetaEstimatorMixin, BaseEstimator
                 estimator,
                 X_new,
                 y,
-                cv=self.cv,
+                cv=self._cv,
                 scoring=self.scoring,
                 n_jobs=self.n_jobs,
             ).mean()
diff --git a/test_edge_cases.py b/test_edge_cases.py
new file mode 100644
index 000000000..2929dccd1
--- /dev/null
+++ b/test_edge_cases.py
@@ -0,0 +1,46 @@
+from sklearn.datasets import make_classification
+from sklearn.feature_selection import SequentialFeatureSelector
+from sklearn.neighbors import KNeighborsClassifier
+from sklearn.model_selection import LeaveOneGroupOut, KFold
+import numpy as np
+
+# Test 1: Original issue - passing splits from cv.split()
+print("=== Test 1: Passing splits from cv.split() ===")
+X, y = make_classification(n_samples=100, n_features=20)
+groups = np.zeros_like(y, dtype=int)
+groups[y.size//2:] = 1
+
+cv = LeaveOneGroupOut()
+splits = cv.split(X, y, groups=groups)
+
+clf = KNeighborsClassifier(n_neighbors=5)
+seq = SequentialFeatureSelector(clf, n_features_to_select=5, scoring='accuracy', cv=splits)
+seq.fit(X, y)
+print("Test 1 passed!")
+
+# Test 2: Passing integer cv (should still work)
+print("\n=== Test 2: Passing integer cv ===")
+seq2 = SequentialFeatureSelector(clf, n_features_to_select=5, scoring='accuracy', cv=5)
+seq2.fit(X, y)
+print("Test 2 passed!")
+
+# Test 3: Passing CV object (should still work)
+print("\n=== Test 3: Passing CV object ===")
+seq3 = SequentialFeatureSelector(clf, n_features_to_select=5, scoring='accuracy', cv=KFold(5))
+seq3.fit(X, y)
+print("Test 3 passed!")
+
+# Test 4: Test with different dataset sizes
+print("\n=== Test 4: Different dataset sizes ===")
+X_small, y_small = make_classification(n_samples=50, n_features=10)
+groups_small = np.zeros_like(y_small, dtype=int)
+groups_small[y_small.size//2:] = 1
+
+cv_small = LeaveOneGroupOut()
+splits_small = cv_small.split(X_small, y_small, groups=groups_small)
+
+seq4 = SequentialFeatureSelector(clf, n_features_to_select=3, scoring='accuracy', cv=splits_small)
+seq4.fit(X_small, y_small)
+print("Test 4 passed!")
+
+print("\nAll tests passed!")
\ No newline at end of file