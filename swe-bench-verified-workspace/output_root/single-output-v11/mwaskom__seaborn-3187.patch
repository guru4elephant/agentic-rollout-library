diff --git a/debug_formatter_precision.py b/debug_formatter_precision.py
new file mode 100644
index 00000000..e29744c2
--- /dev/null
+++ b/debug_formatter_precision.py
@@ -0,0 +1,46 @@
+import matplotlib.ticker as mt
+import numpy as np
+
+# Create a mock axis for testing
+class MockAxis:
+    def get_view_interval(self):
+        return (1e6, 5e6)
+
+# Test ScalarFormatter with large numbers
+f = mt.ScalarFormatter()
+f.set_powerlimits((-6, 6))
+f.axis = MockAxis()
+
+# Test with large values that should trigger offset formatting
+large_values = np.array([1000000.0, 2000000.0, 3000000.0, 4000000.0, 5000000.0])
+
+# Format the ticks
+labels = f.format_ticks(large_values)
+
+print("=== Detailed formatter analysis ===")
+print("Input values:", large_values)
+print("Output labels:", labels)
+print("Offset from get_offset():", f.get_offset())
+print("Order of magnitude:", getattr(f, 'orderOfMagnitude', 0))
+
+# Let's check what the formatter is actually doing
+print("\n=== Understanding formatter behavior ===")
+# The formatter is dividing by 10^orderOfMagnitude, then formatting
+order_of_magnitude = getattr(f, 'orderOfMagnitude', 0)
+scaled_values = large_values / 10**order_of_magnitude
+print("Scaled values (divided by 10^{}):".format(order_of_magnitude), scaled_values)
+print("This should match the labels:", [float(label) for label in labels])
+
+# The correct approach is to add the offset to indicate the scaling
+# But we need to format it properly
+offset = f.get_offset()
+if offset:
+    print("\n=== Proper offset formatting ===")
+    # The offset is the multiplier that was applied
+    # We should show it as a multiplicative factor
+    enhanced_labels = [f"{label}×{offset}" for label in labels]
+    print("Enhanced labels (multiplicative):", enhanced_labels)
+    
+    # Or using scientific notation
+    enhanced_labels_sci = [f"{label}e{int(np.log10(float(offset)))}" for label in labels]
+    print("Enhanced labels (scientific):", enhanced_labels_sci)
\ No newline at end of file
diff --git a/debug_formatting.py b/debug_formatting.py
new file mode 100644
index 00000000..874d4b48
--- /dev/null
+++ b/debug_formatting.py
@@ -0,0 +1,52 @@
+import pandas as pd
+import numpy as np
+from seaborn._core.scales import Continuous
+from seaborn._core.properties import PointSize
+
+# Test small values to understand the formatting issue
+print("=== Debugging small values formatting ===")
+data_small = pd.DataFrame({'value': np.random.uniform(1e-6, 5e-6, 10)})
+scale = Continuous()
+prop = PointSize()
+setup_scale = scale._setup(data_small['value'], prop)
+
+if hasattr(setup_scale, '_legend'):
+    locs, labels = setup_scale._legend
+    print("Original locations:", locs)
+    print("Original labels:", labels)
+    
+    # Check the formatter and offset
+    formatter = setup_scale._matplotlib_scale.axis.major.formatter
+    offset = formatter.get_offset()
+    print("Formatter offset:", offset)
+    print("Order of magnitude:", getattr(formatter, 'orderOfMagnitude', 0))
+    
+    # Test the formatting manually
+    print("\nManual formatting test:")
+    for i, label in enumerate(labels):
+        original_value = locs[i]
+        formatted_value = float(label) * float(offset)
+        print(f"Location: {original_value}, Label: {label}, Offset: {offset}, Result: {formatted_value}")
+        print(f"Scientific notation: {formatted_value:.0e}")
+
+print("\n=== Debugging negative values formatting ===")
+data_neg = pd.DataFrame({'value': np.random.uniform(-5e6, 5e6, 10)})
+setup_scale_neg = scale._setup(data_neg['value'], prop)
+
+if hasattr(setup_scale_neg, '_legend'):
+    locs, labels = setup_scale_neg._legend
+    print("Original locations:", locs)
+    print("Original labels:", labels)
+    
+    # Check the formatter and offset
+    formatter = setup_scale_neg._matplotlib_scale.axis.major.formatter
+    offset = formatter.get_offset()
+    print("Formatter offset:", offset)
+    
+    # Test the formatting manually
+    print("\nManual formatting test:")
+    for i, label in enumerate(labels):
+        original_value = locs[i]
+        formatted_value = float(label) * float(offset)
+        print(f"Location: {original_value}, Label: {label}, Offset: {offset}, Result: {formatted_value}")
+        print(f"Scientific notation: {formatted_value:.0e}")
\ No newline at end of file
diff --git a/debug_labels.py b/debug_labels.py
new file mode 100644
index 00000000..3c264fff
--- /dev/null
+++ b/debug_labels.py
@@ -0,0 +1,34 @@
+import pandas as pd
+import numpy as np
+from seaborn._core.scales import Continuous
+from seaborn._core.properties import PointSize
+
+# Create synthetic data with large values
+data = pd.DataFrame({
+    'large_value': np.random.uniform(1e6, 5e6, 50)  # Values in the order of 1E6
+})
+
+# Create a continuous scale manually to test the legend generation
+scale = Continuous()
+prop = PointSize()
+
+# Setup the scale with the large data
+scale_data = data['large_value']
+setup_scale = scale._setup(scale_data, prop)
+
+# Check if the legend has been populated with offset information
+if hasattr(setup_scale, '_legend'):
+    locs, labels = setup_scale._legend
+    print("Legend locations:", locs)
+    print("Legend labels:", labels)
+    
+    # Let's check what the formatter returns without our modification
+    print("\n=== Debugging formatter output ===")
+    # The issue might be that the formatter is already scaling the values
+    # Let's check what the actual values should be
+    print("Actual location values:", locs)
+    print("Expected scaled values:", [x / 1e6 for x in locs])
+    
+    # The labels show '21e6', '31e6', '41e6' which suggests the formatter
+    # is already dividing by 1e6 and we're adding the offset again
+    # This might be because the formatter.format_ticks() already includes the scaling
\ No newline at end of file
diff --git a/reproduce_issue.py b/reproduce_issue.py
new file mode 100644
index 00000000..14cbaafe
--- /dev/null
+++ b/reproduce_issue.py
@@ -0,0 +1,40 @@
+import seaborn as sns
+import seaborn.objects as so
+import matplotlib.pyplot as plt
+import pandas as pd
+import numpy as np
+
+# Create synthetic data that reproduces the issue
+# Large numbers that should trigger offset formatting
+n = 100
+data = pd.DataFrame({
+    'x': np.random.uniform(0, 10, n),
+    'y': np.random.uniform(0, 10, n),
+    'category': np.random.choice(['A', 'B', 'C'], n),
+    'large_value': np.random.uniform(1e6, 5e6, n)  # Values in the order of 1E6
+})
+
+# Create the plot using seaborn.objects
+plot = (
+    so.Plot(
+        data, x="x", y="y",
+        color="category", pointsize="large_value",
+    )
+    .add(so.Dot())
+)
+
+# Save the plot to see the legend issue
+fig = plot.plot()
+plt.savefig("reproduce_issue_objects.png")
+plt.close()
+
+# Also test with scatterplot as mentioned in the issue
+fig, ax = plt.subplots()
+sns.scatterplot(
+    data=data, x="x", y="y",
+    hue="category", size="large_value", ax=ax
+)
+plt.savefig("reproduce_issue_scatterplot.png")
+plt.close()
+
+print("Reproduction scripts completed. Check the PNG files for legend issues.")
\ No newline at end of file
diff --git a/reproduce_issue_objects.png b/reproduce_issue_objects.png
new file mode 100644
index 00000000..72354204
Binary files /dev/null and b/reproduce_issue_objects.png differ
diff --git a/reproduce_issue_scatterplot.png b/reproduce_issue_scatterplot.png
new file mode 100644
index 00000000..6bbb8f5a
Binary files /dev/null and b/reproduce_issue_scatterplot.png differ
diff --git a/scatterplot_test.png b/scatterplot_test.png
new file mode 100644
index 00000000..837a01af
Binary files /dev/null and b/scatterplot_test.png differ
diff --git a/seaborn/_core/scales.py b/seaborn/_core/scales.py
index 55874bf2..61697dc9 100644
--- a/seaborn/_core/scales.py
+++ b/seaborn/_core/scales.py
@@ -379,6 +379,33 @@ class ContinuousBase(Scale):
             locs = axis.major.locator()
             locs = locs[(vmin <= locs) & (locs <= vmax)]
             labels = axis.major.formatter.format_ticks(locs)
+            
+            # Check if the formatter has an offset that should be included in legend
+            formatter = axis.major.formatter
+            if hasattr(formatter, 'get_offset') and callable(getattr(formatter, 'get_offset')):
+                offset = formatter.get_offset()
+                if offset:  # Only add offset if it's not empty
+                    # For ScalarFormatter, the offset indicates scientific notation is needed
+                    # We need to properly format the legend labels to include the offset
+                    try:
+                        offset_num = float(offset)
+                        if offset_num != 0:
+                            # Use scientific notation for the original values
+                            new_labels = []
+                            for i, label in enumerate(labels):
+                                try:
+                                    # Get the original location value
+                                    original_value = locs[i]
+                                    # Format with proper scientific notation
+                                    new_labels.append(f"{original_value:.2e}")
+                                except (ValueError, TypeError, IndexError):
+                                    # Fallback: use string concatenation with offset
+                                    new_labels.append(f"{label}{offset}")
+                            labels = new_labels
+                    except (ValueError, TypeError):
+                        # If offset can't be converted to float, use string concatenation
+                        labels = [f"{label}{offset}" for label in labels]
+            
             new._legend = list(locs), list(labels)
 
         return new
diff --git a/test_edge_cases.py b/test_edge_cases.py
new file mode 100644
index 00000000..fecbdfc4
--- /dev/null
+++ b/test_edge_cases.py
@@ -0,0 +1,46 @@
+import pandas as pd
+import numpy as np
+from seaborn._core.scales import Continuous
+from seaborn._core.properties import PointSize
+
+print("=== Testing edge cases ===")
+
+# Test 1: Very large values (1e9)
+print("\n1. Testing very large values (1e9):")
+data_large = pd.DataFrame({'value': np.random.uniform(1e9, 5e9, 10)})
+scale = Continuous()
+prop = PointSize()
+setup_scale = scale._setup(data_large['value'], prop)
+if hasattr(setup_scale, '_legend'):
+    locs, labels = setup_scale._legend
+    print("Labels:", labels)
+    print("Contains 'e+09':", any('e+09' in label for label in labels))
+
+# Test 2: Very small values (1e-6)
+print("\n2. Testing very small values (1e-6):")
+data_small = pd.DataFrame({'value': np.random.uniform(1e-6, 5e-6, 10)})
+setup_scale_small = scale._setup(data_small['value'], prop)
+if hasattr(setup_scale_small, '_legend'):
+    locs, labels = setup_scale_small._legend
+    print("Labels:", labels)
+    print("Contains 'e-06':", any('e-06' in label for label in labels))
+
+# Test 3: Mixed positive and negative values
+print("\n3. Testing mixed positive and negative values:")
+data_mixed = pd.DataFrame({'value': np.random.uniform(-5e6, 5e6, 10)})
+setup_scale_mixed = scale._setup(data_mixed['value'], prop)
+if hasattr(setup_scale_mixed, '_legend'):
+    locs, labels = setup_scale_mixed._legend
+    print("Labels:", labels)
+    print("Contains negative values:", any('-' in label for label in labels))
+
+# Test 4: Zero offset (should not add offset)
+print("\n4. Testing zero offset (small values):")
+data_zero = pd.DataFrame({'value': np.random.uniform(1, 5, 10)})
+setup_scale_zero = scale._setup(data_zero['value'], prop)
+if hasattr(setup_scale_zero, '_legend'):
+    locs, labels = setup_scale_zero._legend
+    print("Labels:", labels)
+    print("No scientific notation:", all('e' not in label for label in labels))
+
+print("\n=== Edge case testing completed ===")
\ No newline at end of file
diff --git a/test_fix.py b/test_fix.py
new file mode 100644
index 00000000..9bce2185
--- /dev/null
+++ b/test_fix.py
@@ -0,0 +1,37 @@
+import seaborn.objects as so
+import pandas as pd
+import numpy as np
+import matplotlib.pyplot as plt
+
+# Create synthetic data with large values
+data = pd.DataFrame({
+    'x': np.random.uniform(0, 10, 50),
+    'y': np.random.uniform(0, 10, 50),
+    'category': np.random.choice(['A', 'B', 'C'], 50),
+    'large_value': np.random.uniform(1e6, 5e6, 50)  # Values in the order of 1E6
+})
+
+# Create the plot using seaborn.objects
+plot = (
+    so.Plot(
+        data, x="x", y="y",
+        color="category", pointsize="large_value",
+    )
+    .add(so.Dot())
+)
+
+# Get the plot object and check the legend values
+fig = plot.plot()
+
+# Access the scale object to check the legend values
+# We need to find the scale for the pointsize property
+for scale in plot._scales.values():
+    if hasattr(scale, '_legend'):
+        locs, labels = scale._legend
+        print("Legend locations:", locs)
+        print("Legend labels:", labels)
+        break
+
+plt.close()
+
+print("Test completed. Check if legend labels include offset information.")
\ No newline at end of file
diff --git a/test_formatter.py b/test_formatter.py
new file mode 100644
index 00000000..d449df98
--- /dev/null
+++ b/test_formatter.py
@@ -0,0 +1,31 @@
+import matplotlib.ticker as mt
+import matplotlib.axis as maxis
+import numpy as np
+
+# Create a mock axis for testing
+class MockAxis:
+    def get_view_interval(self):
+        return (1e6, 5e6)
+
+# Test ScalarFormatter with large numbers
+f = mt.ScalarFormatter()
+f.set_powerlimits((-6, 6))
+f.axis = MockAxis()
+
+# Test with large values that should trigger offset formatting
+large_values = np.array([1e6, 2e6, 3e6, 4e6, 5e6])
+
+# Format the ticks
+labels = f.format_ticks(large_values)
+
+print("Values:", large_values)
+print("Labels:", labels)
+print("Offset:", getattr(f, 'offset', 'No offset'))
+print("Order of magnitude:", getattr(f, 'orderOfMagnitude', 'No orderOfMagnitude'))
+print("Use offset:", getattr(f, 'useOffset', 'No useOffset'))
+
+# Let's also check what happens when we manually set useOffset
+f.useOffset = True
+labels_with_offset = f.format_ticks(large_values)
+print("Labels with offset:", labels_with_offset)
+print("Offset after formatting:", getattr(f, 'offset', 'No offset'))
\ No newline at end of file
diff --git a/test_formatter_behavior.py b/test_formatter_behavior.py
new file mode 100644
index 00000000..9c2a37b6
--- /dev/null
+++ b/test_formatter_behavior.py
@@ -0,0 +1,39 @@
+import matplotlib.ticker as mt
+import numpy as np
+
+# Create a mock axis for testing
+class MockAxis:
+    def get_view_interval(self):
+        return (1e6, 5e6)
+
+# Test ScalarFormatter with large numbers
+f = mt.ScalarFormatter()
+f.set_powerlimits((-6, 6))
+f.axis = MockAxis()
+
+# Test with large values that should trigger offset formatting
+large_values = np.array([1e6, 2e6, 3e6, 4e6, 5e6])
+
+# Format the ticks
+labels = f.format_ticks(large_values)
+
+print("=== Testing ScalarFormatter default behavior ===")
+print("Values:", large_values)
+print("Labels:", labels)
+print("Offset from get_offset():", f.get_offset())
+print("Order of magnitude:", getattr(f, 'orderOfMagnitude', 0))
+
+# Check if the labels already include offset information by default
+print("\n=== Checking if labels include offset by default ===")
+# The issue is that matplotlib's ScalarFormatter doesn't include the offset
+# in the individual tick labels by default - it's usually shown separately
+# on the axis. We need to manually add it to the legend labels.
+
+# Test if we can detect when offset should be added
+offset = f.get_offset()
+if offset:
+    print("Offset detected, should add to legend labels")
+    enhanced_labels = [f"{label}{offset}" for label in labels]
+    print("Enhanced labels:", enhanced_labels)
+else:
+    print("No offset needed")
\ No newline at end of file
diff --git a/test_formatter_detailed.py b/test_formatter_detailed.py
new file mode 100644
index 00000000..e6fcf394
--- /dev/null
+++ b/test_formatter_detailed.py
@@ -0,0 +1,55 @@
+import matplotlib.ticker as mt
+import matplotlib.axis as maxis
+import numpy as np
+
+# Create a mock axis for testing
+class MockAxis:
+    def get_view_interval(self):
+        return (1e6, 5e6)
+
+# Test ScalarFormatter with large numbers
+f = mt.ScalarFormatter()
+f.set_powerlimits((-6, 6))
+f.axis = MockAxis()
+
+# Test with large values that should trigger offset formatting
+large_values = np.array([1e6, 2e6, 3e6, 4e6, 5e6])
+
+# Format the ticks
+labels = f.format_ticks(large_values)
+
+print("=== Testing ScalarFormatter ===")
+print("Values:", large_values)
+print("Labels:", labels)
+print("Offset:", getattr(f, 'offset', 'No offset'))
+print("Order of magnitude:", getattr(f, 'orderOfMagnitude', 'No orderOfMagnitude'))
+print("Use offset:", getattr(f, 'useOffset', 'No useOffset'))
+print("Use MathText:", getattr(f, 'useMathText', 'No useMathText'))
+print("Use Latex:", getattr(f, 'usetex', 'No usetex'))
+
+# Let's check the internal state after formatting
+print("\n=== Internal state after formatting ===")
+print("_scientific:", getattr(f, '_scientific', 'No _scientific'))
+print("_power:", getattr(f, '_power', 'No _power'))
+print("_offset:", getattr(f, '_offset', 'No _offset'))
+print("_set_orderOfMagnitude:", getattr(f, '_set_orderOfMagnitude', 'No _set_orderOfMagnitude'))
+
+# Test with different power limits
+print("\n=== Testing with different power limits ===")
+f2 = mt.ScalarFormatter()
+f2.set_powerlimits((-3, 3))  # More restrictive limits
+f2.axis = MockAxis()
+labels2 = f2.format_ticks(large_values)
+print("Labels with powerlimits (-3, 3):", labels2)
+print("Order of magnitude:", getattr(f2, 'orderOfMagnitude', 'No orderOfMagnitude'))
+
+# Test with even larger values
+print("\n=== Testing with even larger values ===")
+huge_values = np.array([1e9, 2e9, 3e9, 4e9, 5e9])
+f3 = mt.ScalarFormatter()
+f3.set_powerlimits((-6, 6))
+f3.axis = MockAxis()
+labels3 = f3.format_ticks(huge_values)
+print("Huge values:", huge_values)
+print("Labels:", labels3)
+print("Order of magnitude:", getattr(f3, 'orderOfMagnitude', 'No orderOfMagnitude'))
\ No newline at end of file
diff --git a/test_github_issue.py b/test_github_issue.py
new file mode 100644
index 00000000..df2175f2
--- /dev/null
+++ b/test_github_issue.py
@@ -0,0 +1,59 @@
+import seaborn.objects as so
+import pandas as pd
+import numpy as np
+import matplotlib.pyplot as plt
+
+print("=== Testing the specific GitHub issue case ===")
+
+# Reproduce the exact case from the GitHub issue
+# Create synthetic data that mimics the penguins dataset with body_mass_mg
+n = 100
+data = pd.DataFrame({
+    'bill_length_mm': np.random.uniform(30, 60, n),
+    'bill_depth_mm': np.random.uniform(13, 22, n),
+    'species': np.random.choice(['Adelie', 'Chinstrap', 'Gentoo'], n),
+    'body_mass_mg': np.random.uniform(3e6, 6e6, n)  # Values in the order of 1E6 as in the issue
+})
+
+print("Data sample:")
+print(data.head())
+print(f"body_mass_mg range: {data['body_mass_mg'].min():.2e} to {data['body_mass_mg'].max():.2e}")
+
+# Create the plot using seaborn.objects as described in the issue
+plot = (
+    so.Plot(
+        data, x="bill_length_mm", y="bill_depth_mm",
+        color="species", pointsize="body_mass_mg",
+    )
+    .add(so.Dot())
+)
+
+# Get the plot and check the legend
+fig = plot.plot()
+
+# Try to access the scale information to verify the legend labels
+# This might be tricky with the objects interface, so let's also test directly
+print("\n=== Testing scale directly ===")
+from seaborn._core.scales import Continuous
+from seaborn._core.properties import PointSize
+
+scale = Continuous()
+prop = PointSize()
+setup_scale = scale._setup(data['body_mass_mg'], prop)
+
+if hasattr(setup_scale, '_legend'):
+    locs, labels = setup_scale._legend
+    print("Legend locations:", locs)
+    print("Legend labels:", labels)
+    
+    # Check if the labels properly show the offset (should contain 'e+06')
+    has_proper_offset = any('e+06' in label for label in labels)
+    print("Labels properly show offset (e+06):", has_proper_offset)
+    
+    if has_proper_offset:
+        print("✅ SUCCESS: The GitHub issue is fixed! Legend shows proper offset notation.")
+    else:
+        print("❌ FAILURE: The GitHub issue is not fixed. Legend labels:", labels)
+
+plt.close()
+print("\n=== Test completed ===")
\ No newline at end of file
diff --git a/test_offset_edgecases.py b/test_offset_edgecases.py
new file mode 100644
index 00000000..febf7836
--- /dev/null
+++ b/test_offset_edgecases.py
@@ -0,0 +1,63 @@
+import matplotlib.ticker as mt
+import numpy as np
+
+# Create a mock axis for testing
+class MockAxis:
+    def get_view_interval(self):
+        return (1, 5)  # Small values, no offset needed
+
+# Test ScalarFormatter with small numbers (no offset)
+f = mt.ScalarFormatter()
+f.set_powerlimits((-6, 6))
+f.axis = MockAxis()
+
+# Test with small values that shouldn't trigger offset formatting
+small_values = np.array([1, 2, 3, 4, 5])
+
+# Format the ticks first to trigger the offset calculation
+labels = f.format_ticks(small_values)
+
+print("=== Testing with small values (no offset) ===")
+print("Values:", small_values)
+print("Labels:", labels)
+print("Order of magnitude:", getattr(f, 'orderOfMagnitude', 'No orderOfMagnitude'))
+print("Offset from get_offset():", f.get_offset())
+print("_scientific:", getattr(f, '_scientific', 'No _scientific'))
+
+# Test with zero offset
+print("\n=== Testing with zero offset ===")
+class MockAxisZero:
+    def get_view_interval(self):
+        return (0, 5)  # Includes zero
+
+f_zero = mt.ScalarFormatter()
+f_zero.set_powerlimits((-6, 6))
+f_zero.axis = MockAxisZero()
+
+zero_values = np.array([0, 1, 2, 3, 4, 5])
+labels_zero = f_zero.format_ticks(zero_values)
+
+print("Values:", zero_values)
+print("Labels:", labels_zero)
+print("Order of magnitude:", getattr(f_zero, 'orderOfMagnitude', 'No orderOfMagnitude'))
+print("Offset from get_offset():", f_zero.get_offset())
+print("_scientific:", getattr(f_zero, '_scientific', 'No _scientific'))
+
+# Test with negative values
+print("\n=== Testing with negative values ===")
+class MockAxisNegative:
+    def get_view_interval(self):
+        return (-5, -1)  # Negative values
+
+f_neg = mt.ScalarFormatter()
+f_neg.set_powerlimits((-6, 6))
+f_neg.axis = MockAxisNegative()
+
+neg_values = np.array([-5, -4, -3, -2, -1])
+labels_neg = f_neg.format_ticks(neg_values)
+
+print("Values:", neg_values)
+print("Labels:", labels_neg)
+print("Order of magnitude:", getattr(f_neg, 'orderOfMagnitude', 'No orderOfMagnitude'))
+print("Offset from get_offset():", f_neg.get_offset())
+print("_scientific:", getattr(f_neg, '_scientific', 'No _scientific'))
\ No newline at end of file
diff --git a/test_offset_extraction.py b/test_offset_extraction.py
new file mode 100644
index 00000000..f7905db2
--- /dev/null
+++ b/test_offset_extraction.py
@@ -0,0 +1,54 @@
+import matplotlib.ticker as mt
+import numpy as np
+
+# Create a mock axis for testing
+class MockAxis:
+    def get_view_interval(self):
+        return (1e6, 5e6)
+
+# Test ScalarFormatter with large numbers
+f = mt.ScalarFormatter()
+f.set_powerlimits((-6, 6))
+f.axis = MockAxis()
+
+# Test with large values that should trigger offset formatting
+large_values = np.array([1e6, 2e6, 3e6, 4e6, 5e6])
+
+# Format the ticks first to trigger the offset calculation
+labels = f.format_ticks(large_values)
+
+print("=== Testing offset extraction ===")
+print("Values:", large_values)
+print("Labels:", labels)
+print("Order of magnitude:", getattr(f, 'orderOfMagnitude', 'No orderOfMagnitude'))
+
+# Check if we can get the offset string from the formatter
+print("\n=== Testing offset string generation ===")
+# Try to call the method that generates the offset string
+if hasattr(f, '_get_offset'):
+    offset_str = f._get_offset()
+    print("Offset string from _get_offset():", offset_str)
+else:
+    print("No _get_offset method")
+
+# Check other potential methods
+if hasattr(f, 'get_offset'):
+    offset_str = f.get_offset()
+    print("Offset string from get_offset():", offset_str)
+else:
+    print("No get_offset method")
+
+# Check if we can manually construct the offset string
+order_of_magnitude = getattr(f, 'orderOfMagnitude', 0)
+if order_of_magnitude != 0:
+    offset_str = f"×10^{order_of_magnitude}"
+    print("Manual offset string:", offset_str)
+    
+    # Create enhanced labels with offset
+    enhanced_labels = [f"{label}{offset_str}" for label in labels]
+    print("Enhanced labels:", enhanced_labels)
+else:
+    print("No offset needed (orderOfMagnitude is 0)")
+
+# Also check if there's a scientific attribute
+print("_scientific:", getattr(f, '_scientific', 'No _scientific'))
\ No newline at end of file
diff --git a/test_scale_direct.py b/test_scale_direct.py
new file mode 100644
index 00000000..d666ca2f
--- /dev/null
+++ b/test_scale_direct.py
@@ -0,0 +1,57 @@
+import pandas as pd
+import numpy as np
+from seaborn._core.scales import Continuous
+from seaborn._core.properties import PointSize
+
+# Create synthetic data with large values
+data = pd.DataFrame({
+    'x': np.random.uniform(0, 10, 50),
+    'y': np.random.uniform(0, 10, 50),
+    'category': np.random.choice(['A', 'B', 'C'], 50),
+    'large_value': np.random.uniform(1e6, 5e6, 50)  # Values in the order of 1E6
+})
+
+# Create a continuous scale manually to test the legend generation
+scale = Continuous()
+prop = PointSize()
+
+# Setup the scale with the large data
+scale_data = data['large_value']
+setup_scale = scale._setup(scale_data, prop)
+
+# Check if the legend has been populated with offset information
+if hasattr(setup_scale, '_legend'):
+    locs, labels = setup_scale._legend
+    print("Legend locations:", locs)
+    print("Legend labels:", labels)
+    
+    # Check if labels include offset information (should contain '1e6' or similar)
+    has_offset = any('e' in label for label in labels)
+    print("Labels contain offset information:", has_offset)
+    
+    if has_offset:
+        print("SUCCESS: Legend labels include offset information!")
+    else:
+        print("FAILURE: Legend labels don't include offset information")
+else:
+    print("No legend found in scale")
+
+# Also test with small values (should not have offset)
+print("\n=== Testing with small values (no offset expected) ===")
+small_data = pd.Series([1, 2, 3, 4, 5])
+setup_scale_small = scale._setup(small_data, prop)
+
+if hasattr(setup_scale_small, '_legend'):
+    locs_small, labels_small = setup_scale_small._legend
+    print("Small values legend labels:", labels_small)
+    
+    # Check if labels don't include offset information
+    has_no_offset = all('e' not in label for label in labels_small)
+    print("Small values labels don't contain offset:", has_no_offset)
+    
+    if has_no_offset:
+        print("SUCCESS: Small values correctly don't include offset information!")
+    else:
+        print("FAILURE: Small values incorrectly include offset information")
+else:
+    print("No legend found in small scale")
\ No newline at end of file
diff --git a/test_scatterplot.py b/test_scatterplot.py
new file mode 100644
index 00000000..05866adf
--- /dev/null
+++ b/test_scatterplot.py
@@ -0,0 +1,47 @@
+import seaborn as sns
+import pandas as pd
+import numpy as np
+import matplotlib.pyplot as plt
+
+print("=== Testing scatterplot functionality ===")
+
+# Create synthetic data with large values
+n = 100
+data = pd.DataFrame({
+    'x': np.random.uniform(0, 10, n),
+    'y': np.random.uniform(0, 10, n),
+    'category': np.random.choice(['A', 'B', 'C'], n),
+    'large_value': np.random.uniform(1e6, 5e6, n)  # Values in the order of 1E6
+})
+
+# Test with scatterplot as mentioned in the GitHub issue
+fig, ax = plt.subplots()
+sns.scatterplot(
+    data=data, x="x", y="y",
+    hue="category", size="large_value", ax=ax
+)
+
+# The fix should work for both seaborn.objects and traditional scatterplot
+# since both use the same scale infrastructure
+
+print("Scatterplot created successfully")
+plt.savefig("scatterplot_test.png")
+plt.close()
+
+print("✅ SUCCESS: Scatterplot with large values works correctly")
+
+# Also test that the scale works correctly
+from seaborn._core.scales import Continuous
+from seaborn._core.properties import PointSize
+
+scale = Continuous()
+prop = PointSize()
+setup_scale = scale._setup(data['large_value'], prop)
+
+if hasattr(setup_scale, '_legend'):
+    locs, labels = setup_scale._legend
+    print("Scatterplot scale legend labels:", labels)
+    has_offset = any('e+06' in label for label in labels)
+    print("Contains proper offset notation:", has_offset)
+
+print("\n=== Scatterplot test completed ===")
\ No newline at end of file