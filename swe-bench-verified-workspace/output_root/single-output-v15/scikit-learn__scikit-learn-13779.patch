diff --git a/reproduce_issue.py b/reproduce_issue.py
new file mode 100644
index 000000000..993fcab02
--- /dev/null
+++ b/reproduce_issue.py
@@ -0,0 +1,22 @@
+import numpy as np
+from sklearn.datasets import load_iris
+from sklearn.ensemble import VotingClassifier
+from sklearn.linear_model import LogisticRegression
+from sklearn.ensemble import RandomForestClassifier
+
+# Reproduce the issue
+X, y = load_iris(return_X_y=True)
+voter = VotingClassifier(
+    estimators=[('lr', LogisticRegression()),
+                ('rf', RandomForestClassifier())]
+)
+voter.fit(X, y, sample_weight=np.ones(y.shape))
+print("First fit successful")
+
+voter.set_params(lr=None)
+try:
+    voter.fit(X, y, sample_weight=np.ones(y.shape))
+    print("Second fit successful")
+except Exception as e:
+    print(f"Error during second fit: {e}")
+    print(f"Error type: {type(e)}")
\ No newline at end of file
diff --git a/sklearn/ensemble/voting.py b/sklearn/ensemble/voting.py
index 7afa7180c..13accdcec 100644
--- a/sklearn/ensemble/voting.py
+++ b/sklearn/ensemble/voting.py
@@ -78,7 +78,7 @@ class _BaseVoting(_BaseComposition, TransformerMixin):
 
         if sample_weight is not None:
             for name, step in self.estimators:
-                if not has_fit_parameter(step, 'sample_weight'):
+                if step is not None and not has_fit_parameter(step, 'sample_weight'):
                     raise ValueError('Underlying estimator \'%s\' does not'
                                      ' support sample weights.' % name)
 
diff --git a/test_edge_cases.py b/test_edge_cases.py
new file mode 100644
index 000000000..c0cfe221e
--- /dev/null
+++ b/test_edge_cases.py
@@ -0,0 +1,71 @@
+import numpy as np
+from sklearn.datasets import load_iris
+from sklearn.ensemble import VotingClassifier
+from sklearn.linear_model import LogisticRegression
+from sklearn.ensemble import RandomForestClassifier
+
+# Test various edge cases
+X, y = load_iris(return_X_y=True)
+
+# Test case 1: All estimators are None (should still raise error)
+print("Test case 1: All estimators None")
+voter1 = VotingClassifier(
+    estimators=[('lr', LogisticRegression()),
+                ('rf', RandomForestClassifier())]
+)
+voter1.set_params(lr=None, rf=None)
+try:
+    voter1.fit(X, y, sample_weight=np.ones(y.shape))
+    print("ERROR: Should have failed!")
+except ValueError as e:
+    print(f"Correctly failed with: {e}")
+
+# Test case 2: One estimator None, one valid (our main fix)
+print("\nTest case 2: One estimator None")
+voter2 = VotingClassifier(
+    estimators=[('lr', LogisticRegression()),
+                ('rf', RandomForestClassifier())]
+)
+voter2.fit(X, y, sample_weight=np.ones(y.shape))
+voter2.set_params(lr=None)
+try:
+    voter2.fit(X, y, sample_weight=np.ones(y.shape))
+    print("Success: Fit with one None estimator worked")
+except Exception as e:
+    print(f"ERROR: Should have worked: {e}")
+
+# Test case 3: No sample weights (should work regardless of None estimators)
+print("\nTest case 3: No sample weights with None estimator")
+voter3 = VotingClassifier(
+    estimators=[('lr', LogisticRegression()),
+                ('rf', RandomForestClassifier())]
+)
+voter3.fit(X, y)
+voter3.set_params(lr=None)
+try:
+    voter3.fit(X, y)  # No sample weights
+    print("Success: Fit without sample weights worked")
+except Exception as e:
+    print(f"ERROR: Should have worked: {e}")
+
+# Test case 4: Let's test with a custom estimator that doesn't support sample weights
+print("\nTest case 4: Custom estimator without sample weight support")
+from sklearn.base import BaseEstimator, ClassifierMixin
+
+class NoSampleWeightEstimator(BaseEstimator, ClassifierMixin):
+    def fit(self, X, y):
+        return self
+    def predict(self, X):
+        return np.zeros(len(X))
+
+voter4 = VotingClassifier(
+    estimators=[('lr', LogisticRegression()),
+                ('nosw', NoSampleWeightEstimator())]
+)
+try:
+    voter4.fit(X, y, sample_weight=np.ones(y.shape))
+    print("ERROR: Should have failed!")
+except ValueError as e:
+    print(f"Correctly failed with: {e}")
+
+print("\nAll tests completed!")
\ No newline at end of file
diff --git a/test_voting_regressor.py b/test_voting_regressor.py
new file mode 100644
index 000000000..e6c2894e4
--- /dev/null
+++ b/test_voting_regressor.py
@@ -0,0 +1,22 @@
+import numpy as np
+from sklearn.datasets import make_regression
+from sklearn.ensemble import VotingRegressor
+from sklearn.linear_model import LinearRegression
+from sklearn.ensemble import RandomForestRegressor
+
+# Test VotingRegressor with the same issue
+X, y = make_regression(n_samples=100, n_features=10, random_state=42)
+voter = VotingRegressor(
+    estimators=[('lr', LinearRegression()),
+                ('rf', RandomForestRegressor())]
+)
+voter.fit(X, y, sample_weight=np.ones(y.shape))
+print("First fit successful")
+
+voter.set_params(lr=None)
+try:
+    voter.fit(X, y, sample_weight=np.ones(y.shape))
+    print("Second fit successful")
+except Exception as e:
+    print(f"Error during second fit: {e}")
+    print(f"Error type: {type(e)}")
\ No newline at end of file