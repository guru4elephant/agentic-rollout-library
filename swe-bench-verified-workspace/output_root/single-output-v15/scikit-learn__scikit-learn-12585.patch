diff --git a/final_verification.py b/final_verification.py
new file mode 100644
index 000000000..6e4c56f6c
--- /dev/null
+++ b/final_verification.py
@@ -0,0 +1,13 @@
+# Exact reproduction case from GitHub issue
+from sklearn.preprocessing import StandardScaler
+from sklearn.base import clone
+
+print("Running exact reproduction case from GitHub issue...")
+try:
+    result = clone(StandardScaler(with_mean=StandardScaler))
+    print("✓ SUCCESS: No error occurred!")
+    print(f"Result type: {type(result)}")
+    print(f"with_mean parameter type: {type(result.with_mean)}")
+    print("The issue has been fixed!")
+except Exception as e:
+    print(f"✗ FAILED: {type(e).__name__}: {e}")
\ No newline at end of file
diff --git a/reproduce_issue.py b/reproduce_issue.py
new file mode 100644
index 000000000..e81f211fd
--- /dev/null
+++ b/reproduce_issue.py
@@ -0,0 +1,10 @@
+from sklearn.preprocessing import StandardScaler
+from sklearn.base import clone
+
+# Test case from the GitHub issue
+try:
+    result = clone(StandardScaler(with_mean=StandardScaler))
+    print("Success: clone worked without error")
+    print(f"Result type: {type(result)}")
+except Exception as e:
+    print(f"Error: {type(e).__name__}: {e}")
\ No newline at end of file
diff --git a/sklearn/base.py b/sklearn/base.py
index 56ffb18bf..34998270c 100644
--- a/sklearn/base.py
+++ b/sklearn/base.py
@@ -48,7 +48,7 @@ def clone(estimator, safe=True):
     # XXX: not handling dictionaries
     if estimator_type in (list, tuple, set, frozenset):
         return estimator_type([clone(e, safe=safe) for e in estimator])
-    elif not hasattr(estimator, 'get_params'):
+    elif not hasattr(estimator, 'get_params') or isinstance(estimator, type):
         if not safe:
             return copy.deepcopy(estimator)
         else:
diff --git a/test_edge_cases.py b/test_edge_cases.py
new file mode 100644
index 000000000..b3700b2da
--- /dev/null
+++ b/test_edge_cases.py
@@ -0,0 +1,66 @@
+from sklearn.preprocessing import StandardScaler
+from sklearn.linear_model import LinearRegression
+from sklearn.base import clone
+import numpy as np
+
+print("Testing various edge cases...")
+
+# Test 1: Original issue case
+print("\n1. Testing original issue case:")
+try:
+    result = clone(StandardScaler(with_mean=StandardScaler))
+    print(f"✓ Success: {type(result)}")
+except Exception as e:
+    print(f"✗ Error: {e}")
+
+# Test 2: Multiple estimator types as parameters
+print("\n2. Testing multiple estimator types:")
+try:
+    result = clone(StandardScaler(with_mean=StandardScaler, with_std=LinearRegression))
+    print(f"✓ Success: {type(result)}")
+    print(f"  Parameters: with_mean={type(result.with_mean)}, with_std={type(result.with_std)}")
+except Exception as e:
+    print(f"✗ Error: {e}")
+
+# Test 3: Normal estimator cloning (should still work)
+print("\n3. Testing normal estimator cloning:")
+try:
+    result = clone(StandardScaler())
+    print(f"✓ Success: {type(result)}")
+except Exception as e:
+    print(f"✗ Error: {e}")
+
+# Test 4: Nested estimator types
+print("\n4. Testing nested estimator types:")
+try:
+    # Create a custom class that has estimator types as attributes
+    class CustomEstimator:
+        def __init__(self):
+            self.estimator_class = StandardScaler
+            self.normal_param = "test"
+        
+        def get_params(self, deep=True):
+            return {'estimator_class': self.estimator_class, 'normal_param': self.normal_param}
+        
+        def set_params(self, **params):
+            for key, value in params.items():
+                setattr(self, key, value)
+            return self
+    
+    custom = CustomEstimator()
+    result = clone(custom)
+    print(f"✓ Success: {type(result)}")
+    print(f"  estimator_class type: {type(result.estimator_class)}")
+except Exception as e:
+    print(f"✗ Error: {e}")
+
+# Test 5: Regular Python types (should work as before)
+print("\n5. Testing regular Python types:")
+try:
+    result = clone(StandardScaler(with_mean=True, with_std=False))
+    print(f"✓ Success: {type(result)}")
+    print(f"  Parameters: with_mean={result.with_mean}, with_std={result.with_std}")
+except Exception as e:
+    print(f"✗ Error: {e}")
+
+print("\nAll tests completed!")
\ No newline at end of file
diff --git a/test_safe_parameter.py b/test_safe_parameter.py
new file mode 100644
index 000000000..9bbe14cf8
--- /dev/null
+++ b/test_safe_parameter.py
@@ -0,0 +1,35 @@
+from sklearn.preprocessing import StandardScaler
+from sklearn.base import clone
+
+print("Testing safe parameter behavior...")
+
+# Test with safe=True (default)
+print("\n1. Testing with safe=True (default):")
+try:
+    result = clone(StandardScaler(with_mean=StandardScaler), safe=True)
+    print(f"✓ Success: {type(result)}")
+except Exception as e:
+    print(f"✗ Error: {e}")
+
+# Test with safe=False
+print("\n2. Testing with safe=False:")
+try:
+    result = clone(StandardScaler(with_mean=StandardScaler), safe=False)
+    print(f"✓ Success: {type(result)}")
+except Exception as e:
+    print(f"✗ Error: {e}")
+
+# Test with a non-estimator type that doesn't have get_params
+print("\n3. Testing with a regular Python class (should use deepcopy):")
+class RegularClass:
+    def __init__(self, value):
+        self.value = value
+
+try:
+    result = clone(StandardScaler(with_mean=RegularClass), safe=False)
+    print(f"✓ Success: {type(result)}")
+    print(f"  with_mean type: {type(result.with_mean)}")
+except Exception as e:
+    print(f"✗ Error: {e}")
+
+print("\nAll safe parameter tests completed!")
\ No newline at end of file